{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import dill\n",
    "import base64\n",
    "import requests\n",
    "import PIL \n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "import tarfile\n",
    "import os.path\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import Figure\n",
    "from shutil import rmtree\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlretrieve\n",
    "from tensorflow.image import resize\n",
    "from tensorflow.data import Dataset \n",
    "from tensorflow.keras import Model, Sequential, Input\n",
    "from tensorflow.keras.optimizers import SGD \n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, smart_resize,array_to_img,\\\n",
    "    ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.applications.efficientnet import EfficientNetB1, EfficientNetB2, EfficientNetB3,\\\n",
    "    EfficientNetB4, EfficientNetB5, EfficientNetB6, EfficientNetB7\n",
    "from tensorflow.data.experimental import save, cardinality\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomContrast\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.distribute import get_strategy\n",
    "from tensorflow.keras.models import load_model\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAIN_STORAGE=\"./capstonedump\"\n",
    "PHOTOS_SOURCE=f\"{MAIN_STORAGE}/photos\"\n",
    "LATENT_VECTORS_STORAGE=f\"{MAIN_STORAGE}/latents\"\n",
    "TFMODELS_STORAGE=f\"{MAIN_STORAGE}/tfmodels\"\n",
    "PLOTS_STORAGE=f\"{MAIN_STORAGE}/plots\"\n",
    "LISTING_SOURCE=f\"{MAIN_STORAGE}/listing-images\"\n",
    "CATEGORY=\"kitchen\"\n",
    "BATCH=(20, 30, 50)\n",
    "IMG_SIZE={\n",
    "    \"EfficientNetB0\":224,\n",
    "    \"EfficientNetB1\":240,\n",
    "    \"EfficientNetB2\":260,\n",
    "    \"EfficientNetB3\":300,\n",
    "    \"EfficientNetB4\":380,\n",
    "    \"EfficientNetB5\":456,\n",
    "    \"EfficientNetB6\":528,\n",
    "    \"EfficientNetB7\":600, \n",
    "    \"InceptionV3\":299\n",
    "} \n",
    "LATENT_EPOCHS=1\n",
    "N_CLASSES=3\n",
    "N_COLORS=3\n",
    "STRATEGY=get_strategy() \n",
    "OPTIMIZATION_SUBDATASETS=(\"training\", \"validation\")\n",
    "MODEL_SPEC=\"EfficientNetB5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unzip_imageset():\n",
    "    if os.path.isdir(\"./capstonedump/photos\"):\n",
    "        ! rm -R ./capstonedump/photos\n",
    "    ! tar -xf ./capstonedump/large-imageset.tar.gz -C ./capstonedump/\n",
    "unzip_imageset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process jpg jpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### imgprep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "class ImgPrep: \n",
    "    def decode_base64(in_save, in_encription):\n",
    "            with open(in_save, 'wb') as outfile_:\n",
    "                stripped=re.sub('data:image/jpeg;base64,', '', in_encription)\n",
    "                decoded=base64.b64decode((stripped))\n",
    "                outfile_.write(decoded) \n",
    "            \n",
    "    def decript_gstatic(in_save, in_gstatic):\n",
    "        browser.get(in_gstatic)\n",
    "        soup=BeautifulSoup(browser.page_source, 'lxml')\n",
    "        encriptedimg=[img[attr]  \n",
    "                      for attr in ['src', 'data-src']  \n",
    "                      for img in soup.find_all('img', \n",
    "                                               {attr: True})]\n",
    "        urlretrieve(encriptedimg[0] , in_save)\n",
    "\n",
    "    def download(in_imglinks, in_category=\"lux-kitchen\"):\n",
    "        base64_save=f\"./capstonedump/base64-{in_category}\"+\"-{}.jpeg\"\n",
    "        gstatic_save=f\"./capstonedump/gstatic-{in_category}\"+\"-{}.jpg\"\n",
    "\n",
    "        [ImgPrep.decode_base64(base64_save.format(index), unit)\n",
    "         if \"data:image/jpeg;base64,/9j\"  \n",
    "         in unit \n",
    "         else urlretrieve(unit, gstatic_save.format(index))\n",
    "         for index, unit \n",
    "         in enumerate(luxlinks)]\n",
    "\n",
    "    def digitize(in_imgfiles):\n",
    "        return [img_to_array(load_img(unit)) \n",
    "                for unit in in_imgfiles]\n",
    "\n",
    "    def rescale(in_pixelstack, img_size = IMG_SIZE[0], in_save=\"./capstonedump/resized.pkd\"):\n",
    "        return [smart_resize(unit, size=(IMG_SIZE[0], IMG_SIZE[0])) \n",
    "                    for unit \n",
    "                    in digitized]\n",
    "    \n",
    "    def label_from_file(in_file):\n",
    "        possession_=(re\n",
    "                    .search(\n",
    "                        \"|\".join(LABELS.keys()),\n",
    "                        in_file) \n",
    "                    .group())\n",
    "        return LABELS[possession_] \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### first img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`imgfiles=os.listdir('./capstonedump/')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`jpgpaths=[\"./capstonedump/\"+file for file in os.listdir('./capstonedump/') if file.endswith('.jpg')]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`jpgloaded=load_img(jpgpaths[0])`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`analog=img_to_array(jpgloaded)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`rescaled=smart_resize(analog, size=(224, 224))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`array_to_img(rescaled)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### tf preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Assume a set of jpgs and jpegs (w. labels)\n",
    "\n",
    "Preprocess imgs via tf:\n",
    "1. load pkd img links (base64 jpegs and gstatic jpg)\n",
    "2. convert into arrays ($N \\times K \\times K$)\n",
    "3. one hot encode labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### merge classes && make labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```\n",
    "['allsrc-luxurious-kitchen.pkd',\n",
    " 'allsrc-dilapidated-kitchen.pkd',\n",
    " 'allsrc-home-kitchen.pkd']\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "[os.remove(f\"./capstonedump/{unit}\")\n",
    " for unit in os.listdir(\"./capstonedump/\") \n",
    " if any(map(unit.__contains__, [\"jpg\", \"jpeg\"]))]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### arrayfy imgs put into labelled classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "[os.mkdir(f\"{DATASET_SAVEDIR}{i}\") for i in range(N_CLASSES)]\n",
    "[os.mkdir(f\"{PHOTO_SAVEDIR}{i}/\") for i in range(N_CLASSES)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "links_in_classes=[(dill.load(open(f\"{CORE_SAVEDIR}{file}\", \"rb\")),  \n",
    "                    ImgPrep.label_from_file(file))\n",
    "                        for file in os.listdir(CORE_SAVEDIR) \n",
    "                        if file.startswith(\"allsrc\")  \n",
    "                            and file.endswith(\".pkd\")]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "[ImgPrep.decode_base64(f\"{PHOTO_SAVEDIR}{label}/{index}.jpeg\", unit)\n",
    "    if \"data:image/jpeg;base64,/9j\" in unit\n",
    "    else urlretrieve(unit, f\"{PHOTO_SAVEDIR}{label}/{index}.jpg\")\n",
    "    for links, label in links_in_classes\n",
    "    for index, unit in enumerate(links)]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "[np.save(f\"{DATASET_SAVEDIR}{label}/{index}.npy\",  \n",
    "        img_to_array(load_img(f\"{PHOTO_SAVEDIR}{label}/{file}\")),\n",
    "        allow_pickle=True)\n",
    "    for label in os.listdir(f\"{PHOTO_SAVEDIR}\")\n",
    "    for index, file in enumerate(os.listdir(f\"{PHOTO_SAVEDIR}{label}\"))]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python \n",
    "[os.remove(f\"{CORE_SAVEDIR}{file}\") \n",
    " for file in os.listdir(CORE_SAVEDIR) \n",
    " if file.endswith(('.jpg', '.jpeg'))]\n",
    "labels_and_images()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "#### decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "class ImgDecoder:\n",
    "    def make_diretories():\n",
    "        [os.mkdir(f\"{DATASET_SAVEDIR}{i}\")  \n",
    "         for i in range(N_CLASSES)]\n",
    "        [os.mkdir(f\"{PHOTO_SAVEDIR}{i}/\") \n",
    "         for i in range(N_CLASSES)]\n",
    "        \n",
    "    def links_in_classes():\n",
    "        return [(dill.load(open(f\"{CORE_SAVEDIR}{file}\",  \n",
    "                                \"rb\")),  \n",
    "                 ImgPrep.label_from_file(file))\n",
    "                    for file  \n",
    "                    in os.listdir(CORE_SAVEDIR) \n",
    "                    if file.startswith(\"allsrc\")  \n",
    "                        and file.endswith(\".pkd\")]\n",
    "    \n",
    "    def decode_from_links():\n",
    "        [ImgPrep.decode_base64(f\"{PHOTO_SAVEDIR}{label}/{index}.jpeg\", unit)\n",
    "            if \"data:image/jpeg;base64,/9j\" \n",
    "            in unit\n",
    "            else urlretrieve(unit, f\"{PHOTO_SAVEDIR}{label}/{index}.jpg\")\n",
    "            for links, label  \n",
    "            in ImgDecoder.links_in_classes()\n",
    "            for index, unit  \n",
    "            in enumerate(links)]\n",
    "    \n",
    "    def run():\n",
    "        ImgDecoder.make_diretories()\n",
    "        ImgDecoder.decode_from_links()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load images && tf reprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def split_factory(**KWARGS):\n",
    "    return image_dataset_from_directory(\n",
    "                KWARGS[\"image_source\"], \n",
    "                labels=\"inferred\", \n",
    "                label_mode=\"int\",\n",
    "                class_names=list(map(str,  \n",
    "                                     range(N_CLASSES))),\n",
    "                color_mode=\"rgb\",\n",
    "                image_size=(KWARGS['image_size'],  \n",
    "                            KWARGS['image_size']),\n",
    "                subset=KWARGS[\"subset\"],\n",
    "                shuffle=True,\n",
    "                batch_size=KWARGS['batch_size'],\n",
    "                seed=1,\n",
    "                validation_split=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 26720 files belonging to 3 classes.\n",
      "Using 21376 files for training.\n",
      "Found 26720 files belonging to 3 classes.\n",
      "Using 5344 files for validation.\n"
     ]
    }
   ],
   "source": [
    "split={subset: \n",
    "           split_factory(image_source=PHOTOS_SOURCE,\n",
    "                         subset=subset, \n",
    "                         image_size=IMG_SIZE[MODEL_SPEC], \n",
    "                         batch_size=BATCH[0]) \n",
    "       for subset  \n",
    "       in OPTIMIZATION_SUBDATASETS} \n",
    "\n",
    "distributed={index: \n",
    "             STRATEGY.experimental_distribute_dataset(dataset)\n",
    "             for index, dataset in split.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "#### notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "```python\n",
    "Found 2823 files belonging to 3 classes.\n",
    "Using 2400 files for training.\n",
    "Found 2823 files belonging to 3 classes.\n",
    "Using 423 files for validation.\n",
    "CPU times: user 309 ms, sys: 51.3 ms, total: 360 ms\n",
    "Wall time: 316 ms\n",
    "    \n",
    "inceptionv3 ? b?\n",
    "```\n",
    "```python\n",
    "# include_top=False will discard avg_pool before prediction layer\n",
    "inception = tf.keras.applications.inception_v3.InceptionV3(include_top=True, input_shape=(299, 299, 3))\n",
    "inception = tf.keras.Model([inception.input], [inception.layers[-2].output]) # manually discard prediction layer\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 1 µs, total: 7 µs\n",
      "Wall time: 9.54 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def pretrained_factory(**KWARGS):\n",
    "    clear_session()\n",
    "    expert=EfficientNetB5(\n",
    "                include_top=True, \n",
    "                input_shape=(KWARGS[\"img_size\"],  \n",
    "                             KWARGS[\"img_size\"],  \n",
    "                             N_COLORS))\n",
    "    pretrained=tf.keras.Model([expert.input],\n",
    "                   [expert.layers[-KWARGS[\"num_layers_to_exclude\"]] \n",
    "                          .output])\n",
    "    pretrained.trainable=False\n",
    "    pipeline=Sequential()\n",
    "    pipeline.add(RandomFlip('horizontal', \n",
    "                            seed=1,\n",
    "                            input_shape=(KWARGS['img_size'], \n",
    "                                         KWARGS['img_size'], \n",
    "                                         N_COLORS)))\n",
    "    pipeline.add(RandomRotation(KWARGS['rotation_factor'], \n",
    "                                seed=1))\n",
    "    pipeline.add(RandomContrast(KWARGS['contrast_factor'], \n",
    "                                seed=1))\n",
    "    pipeline.add(pretrained)\n",
    "    pipeline.summary()\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "random_flip (RandomFlip)     (None, 456, 456, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_rotation (RandomRotat (None, 456, 456, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_contrast (RandomContr (None, 456, 456, 3)       0         \n",
      "_________________________________________________________________\n",
      "functional_1 (Functional)    (None, 2048)              28513527  \n",
      "=================================================================\n",
      "Total params: 28,513,527\n",
      "Trainable params: 0\n",
      "Non-trainable params: 28,513,527\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transfer_student=pretrained_factory(\n",
    "                     img_size=IMG_SIZE[MODEL_SPEC],\n",
    "                     num_layers_to_exclude=2,\n",
    "                     rotation_factor=0.1,\n",
    "                     contrast_factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 7.15 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def clean_directories_in(in_dir, **KWARGS):\n",
    "    if in_dir:\n",
    "        rmtree(in_dir)\n",
    "    os.mkdir(in_dir)\n",
    "    [os.mkdir(f\"{in_dir}/{subdirectory}\")  \n",
    "         for subdirectory \n",
    "         in KWARGS['subdir'] ]\n",
    "\n",
    "def calculate_latents(in_distributed_dataset, \n",
    "                      in_pretrained_model, \n",
    "                      **KWARGS\n",
    "                     ): \n",
    "    SAVEPATH_=\"{}/{}/vectors-per-step-{}.npy\"\n",
    "    with STRATEGY.scope():\n",
    "        for subset, dataset in in_distributed_dataset.items():\n",
    "            for _ in range(LATENT_EPOCHS):\n",
    "                for index, bundle in enumerate(\n",
    "                                         iter(\n",
    "                                             dataset)):\n",
    "                    try:\n",
    "                        latent_per_step=(in_pretrained_model \n",
    "                                         .predict(\n",
    "                                             tf.convert_to_tensor(bundle[0]), \n",
    "                                             verbose=0))\n",
    "                        clear_session()\n",
    "                        gc.collect()\n",
    "                    except tf.errors.InvalidArgumentError: \n",
    "                        pass\n",
    "                    with open(SAVEPATH_.format(KWARGS[\"latents_save_location\"],\n",
    "                                               subset, \n",
    "                                               index),  \n",
    "                              \"wb\") \\\n",
    "                        as fout_:\n",
    "                        np.save(fout_,\n",
    "                                latent_per_step,\n",
    "                                allow_pickle=True) \n",
    "                    del latent_per_step\n",
    "\n",
    "def compress_latents(in_path, out_path):\n",
    "    with tarfile.open(out_path, \"w:gz\") as tar_:\n",
    "        tar_.add(in_path, \n",
    "                 arcname=os.path.basename(in_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "clean_directories_in(LATENT_VECTORS_STORAGE, \n",
    "                     subdir=OPTIMIZATION_SUBDATASETS)\n",
    "\n",
    "calculate_latents(distributed,\n",
    "                  transfer_student,\n",
    "                  latents_save_location=LATENT_VECTORS_STORAGE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compress_latents(LATENT_VECTORS_STORAGE, f\"{MAIN_STORAGE}/latents-large-{MODEL_SPEC}.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 6.91 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def load_latent_vectors(in_load_path, \n",
    "                        **KWARGS\n",
    "                       ):\n",
    "    unsorted=[(int(re.split(\"\\-|\\.\", file)[-2]), \n",
    "               np.load(f'{in_load_path}/{file}'))\n",
    "              for file \n",
    "              in os.listdir(in_load_path)]\n",
    "    ordered=sorted(unsorted,  \n",
    "                   key = lambda index_dataset: \n",
    "                             index_dataset[0])\n",
    "    \n",
    "    stacked=(np.vstack(\n",
    "                [dataset  \n",
    "                 for index, dataset  \n",
    "                 in ordered]))\n",
    "    return stacked \n",
    "def one_hot_labels(in_label_images):\n",
    "    \"\"\"\n",
    "    :in_label_images: \n",
    "        BatchDataset: image arrays (batch, pixels, pixels, colors) \n",
    "            && labels\n",
    "    \"\"\"\n",
    "    unpacked_=list(\n",
    "                 chain(\n",
    "                     *[labels \n",
    "                       for images, labels \n",
    "                       in in_label_images])) \n",
    "    return tf.one_hot(unpacked_,  \n",
    "                      depth=N_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.2 s, sys: 4.83 s, total: 39 s\n",
      "Wall time: 57.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "try:\n",
    "    latents_and_labels\n",
    "    del latents_and_labels\n",
    "    gc.collect()\n",
    "except NameError:\n",
    "    pass \n",
    "\n",
    "latents_and_labels={subset:\n",
    "                    (load_latent_vectors(f\"{LATENT_VECTORS_STORAGE}/{subset}/\"),\n",
    "                     one_hot_labels(split[subset]))\n",
    "                         for subset in OPTIMIZATION_SUBDATASETS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_facotory(**KWARGS):\n",
    "    classifier=Sequential()\n",
    "    classifier.add(\n",
    "        Dense(\n",
    "            N_CLASSES, \n",
    "            name=\"softmax\",\n",
    "            activation=\"softmax\",\n",
    "            input_dim=KWARGS['input_dim']))\n",
    "\n",
    "    classifier.compile(\n",
    "        optimizer=SGD(lr=0.0001,  \n",
    "                      momentum=1.,  \n",
    "                      nesterov=True),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.7541 - accuracy: 0.7455 - val_loss: 0.8062 - val_accuracy: 0.7893\n",
      "Epoch 2/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.8343 - accuracy: 0.8075 - val_loss: 0.9023 - val_accuracy: 0.8073\n",
      "Epoch 3/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.8031 - accuracy: 0.8043 - val_loss: 0.8648 - val_accuracy: 0.7979\n",
      "Epoch 4/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.8214 - accuracy: 0.7965 - val_loss: 0.9104 - val_accuracy: 0.7891\n",
      "Epoch 5/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.7678 - accuracy: 0.8082 - val_loss: 0.9144 - val_accuracy: 0.7904\n",
      "Epoch 6/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.7927 - accuracy: 0.8082 - val_loss: 1.0478 - val_accuracy: 0.7667\n",
      "Epoch 7/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.7641 - accuracy: 0.8205 - val_loss: 0.9729 - val_accuracy: 0.7979\n",
      "Epoch 8/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.7858 - accuracy: 0.8161 - val_loss: 1.0594 - val_accuracy: 0.7798\n",
      "Epoch 9/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.7645 - accuracy: 0.8220 - val_loss: 1.0704 - val_accuracy: 0.8007\n",
      "Epoch 10/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.8443 - accuracy: 0.8229 - val_loss: 1.1259 - val_accuracy: 0.7945\n",
      "Epoch 11/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.7905 - accuracy: 0.8315 - val_loss: 1.2493 - val_accuracy: 0.7880\n",
      "Epoch 12/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.8365 - accuracy: 0.8156 - val_loss: 1.1909 - val_accuracy: 0.7650\n",
      "Epoch 13/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.7845 - accuracy: 0.8346 - val_loss: 1.2836 - val_accuracy: 0.7799\n",
      "Epoch 14/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.8589 - accuracy: 0.8285 - val_loss: 1.3496 - val_accuracy: 0.7938\n",
      "Epoch 15/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.8462 - accuracy: 0.8394 - val_loss: 1.4813 - val_accuracy: 0.7812\n",
      "Epoch 16/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.9223 - accuracy: 0.8248 - val_loss: 1.4980 - val_accuracy: 0.7644\n",
      "Epoch 17/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.9715 - accuracy: 0.8350 - val_loss: 1.4715 - val_accuracy: 0.7900\n",
      "Epoch 18/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.9938 - accuracy: 0.8364 - val_loss: 1.5730 - val_accuracy: 0.7816\n",
      "Epoch 19/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.9777 - accuracy: 0.8350 - val_loss: 1.7070 - val_accuracy: 0.7771\n",
      "Epoch 20/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.9713 - accuracy: 0.8415 - val_loss: 1.6554 - val_accuracy: 0.7831\n",
      "Epoch 21/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.9539 - accuracy: 0.8371 - val_loss: 1.8634 - val_accuracy: 0.7674\n",
      "Epoch 22/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.9790 - accuracy: 0.8399 - val_loss: 1.9211 - val_accuracy: 0.7594\n",
      "Epoch 23/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 0.9904 - accuracy: 0.8357 - val_loss: 1.8911 - val_accuracy: 0.7586\n",
      "Epoch 24/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.0618 - accuracy: 0.8336 - val_loss: 2.1055 - val_accuracy: 0.7717\n",
      "Epoch 25/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.1752 - accuracy: 0.8415 - val_loss: 2.0035 - val_accuracy: 0.8074\n",
      "Epoch 26/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.1495 - accuracy: 0.8358 - val_loss: 2.1373 - val_accuracy: 0.7925\n",
      "Epoch 27/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.2222 - accuracy: 0.8289 - val_loss: 2.0514 - val_accuracy: 0.7891\n",
      "Epoch 28/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.3691 - accuracy: 0.8241 - val_loss: 2.8167 - val_accuracy: 0.7129\n",
      "Epoch 29/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.2845 - accuracy: 0.8328 - val_loss: 2.1778 - val_accuracy: 0.7962\n",
      "Epoch 30/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.3116 - accuracy: 0.8430 - val_loss: 2.3398 - val_accuracy: 0.8035\n",
      "Epoch 31/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.2505 - accuracy: 0.8474 - val_loss: 2.5629 - val_accuracy: 0.7532\n",
      "Epoch 32/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.3018 - accuracy: 0.8387 - val_loss: 2.4522 - val_accuracy: 0.7940\n",
      "Epoch 33/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.3128 - accuracy: 0.8453 - val_loss: 2.4628 - val_accuracy: 0.7856\n",
      "Epoch 34/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.3994 - accuracy: 0.8376 - val_loss: 2.7026 - val_accuracy: 0.7827\n",
      "Epoch 35/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5313 - accuracy: 0.8391 - val_loss: 2.6901 - val_accuracy: 0.8016\n",
      "Epoch 36/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5304 - accuracy: 0.8429 - val_loss: 2.8287 - val_accuracy: 0.7732\n",
      "Epoch 37/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5414 - accuracy: 0.8251 - val_loss: 3.1117 - val_accuracy: 0.7723\n",
      "Epoch 38/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.6511 - accuracy: 0.8406 - val_loss: 3.0807 - val_accuracy: 0.7728\n",
      "Epoch 39/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5315 - accuracy: 0.8394 - val_loss: 2.8875 - val_accuracy: 0.7874\n",
      "Epoch 40/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.6339 - accuracy: 0.8469 - val_loss: 3.1276 - val_accuracy: 0.8000\n",
      "Epoch 41/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.7529 - accuracy: 0.8466 - val_loss: 2.9747 - val_accuracy: 0.7968\n",
      "Epoch 42/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5943 - accuracy: 0.8473 - val_loss: 3.4972 - val_accuracy: 0.7661\n",
      "Epoch 43/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5443 - accuracy: 0.8470 - val_loss: 3.5843 - val_accuracy: 0.7833\n",
      "Epoch 44/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5745 - accuracy: 0.8479 - val_loss: 3.4233 - val_accuracy: 0.7665\n",
      "Epoch 45/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5004 - accuracy: 0.8402 - val_loss: 3.3250 - val_accuracy: 0.7779\n",
      "Epoch 46/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.4127 - accuracy: 0.8617 - val_loss: 3.5345 - val_accuracy: 0.7923\n",
      "Epoch 47/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.4908 - accuracy: 0.8558 - val_loss: 3.2856 - val_accuracy: 0.7891\n",
      "Epoch 48/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.4442 - accuracy: 0.8440 - val_loss: 3.4307 - val_accuracy: 0.7646\n",
      "Epoch 49/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.4239 - accuracy: 0.8517 - val_loss: 3.6017 - val_accuracy: 0.7747\n",
      "Epoch 50/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.3936 - accuracy: 0.8582 - val_loss: 3.4878 - val_accuracy: 0.7717\n",
      "Epoch 51/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.4280 - accuracy: 0.8454 - val_loss: 3.4436 - val_accuracy: 0.7799\n",
      "Epoch 52/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.4681 - accuracy: 0.8667 - val_loss: 3.7257 - val_accuracy: 0.7979\n",
      "Epoch 53/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.4680 - accuracy: 0.8618 - val_loss: 3.6174 - val_accuracy: 0.7747\n",
      "Epoch 54/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5524 - accuracy: 0.8395 - val_loss: 3.7910 - val_accuracy: 0.7764\n",
      "Epoch 55/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.4461 - accuracy: 0.8605 - val_loss: 4.0004 - val_accuracy: 0.7829\n",
      "Epoch 56/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5122 - accuracy: 0.8627 - val_loss: 3.9842 - val_accuracy: 0.7747\n",
      "Epoch 57/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.6172 - accuracy: 0.8438 - val_loss: 4.1078 - val_accuracy: 0.7625\n",
      "Epoch 58/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5463 - accuracy: 0.8595 - val_loss: 4.0944 - val_accuracy: 0.7936\n",
      "Epoch 59/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.6203 - accuracy: 0.8578 - val_loss: 3.9514 - val_accuracy: 0.7803\n",
      "Epoch 60/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.6064 - accuracy: 0.8440 - val_loss: 4.1225 - val_accuracy: 0.7732\n",
      "Epoch 61/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5254 - accuracy: 0.8645 - val_loss: 4.2133 - val_accuracy: 0.7972\n",
      "Epoch 62/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5237 - accuracy: 0.8656 - val_loss: 4.1112 - val_accuracy: 0.7745\n",
      "Epoch 63/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5741 - accuracy: 0.8489 - val_loss: 4.2589 - val_accuracy: 0.7637\n",
      "Epoch 64/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.4509 - accuracy: 0.8624 - val_loss: 4.3236 - val_accuracy: 0.7799\n",
      "Epoch 65/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5011 - accuracy: 0.8649 - val_loss: 4.2842 - val_accuracy: 0.7738\n",
      "Epoch 66/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5643 - accuracy: 0.8510 - val_loss: 4.4084 - val_accuracy: 0.7618\n",
      "Epoch 67/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.4487 - accuracy: 0.8643 - val_loss: 4.3123 - val_accuracy: 0.7893\n",
      "Epoch 68/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.6164 - accuracy: 0.8605 - val_loss: 4.2962 - val_accuracy: 0.7784\n",
      "Epoch 69/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5704 - accuracy: 0.8504 - val_loss: 4.4723 - val_accuracy: 0.7597\n",
      "Epoch 70/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.3891 - accuracy: 0.8649 - val_loss: 4.5271 - val_accuracy: 0.7769\n",
      "Epoch 71/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5029 - accuracy: 0.8631 - val_loss: 4.6926 - val_accuracy: 0.7687\n",
      "Epoch 72/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.4957 - accuracy: 0.8525 - val_loss: 4.6821 - val_accuracy: 0.7551\n",
      "Epoch 73/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.4531 - accuracy: 0.8608 - val_loss: 4.5769 - val_accuracy: 0.7777\n",
      "Epoch 74/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5095 - accuracy: 0.8659 - val_loss: 4.5643 - val_accuracy: 0.7775\n",
      "Epoch 75/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.4988 - accuracy: 0.8613 - val_loss: 4.6616 - val_accuracy: 0.7728\n",
      "Epoch 76/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5177 - accuracy: 0.8636 - val_loss: 4.6150 - val_accuracy: 0.7837\n",
      "Epoch 77/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5150 - accuracy: 0.8643 - val_loss: 4.6769 - val_accuracy: 0.7790\n",
      "Epoch 78/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5223 - accuracy: 0.8590 - val_loss: 4.8045 - val_accuracy: 0.7719\n",
      "Epoch 79/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5312 - accuracy: 0.8592 - val_loss: 4.7251 - val_accuracy: 0.7805\n",
      "Epoch 80/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5872 - accuracy: 0.8673 - val_loss: 4.7993 - val_accuracy: 0.7869\n",
      "Epoch 81/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5399 - accuracy: 0.8616 - val_loss: 4.9331 - val_accuracy: 0.7646\n",
      "Epoch 82/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5597 - accuracy: 0.8586 - val_loss: 4.9695 - val_accuracy: 0.7715\n",
      "Epoch 83/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.6148 - accuracy: 0.8616 - val_loss: 5.0878 - val_accuracy: 0.7754\n",
      "Epoch 84/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5712 - accuracy: 0.8601 - val_loss: 5.1324 - val_accuracy: 0.7642\n",
      "Epoch 85/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.6339 - accuracy: 0.8496 - val_loss: 5.0903 - val_accuracy: 0.7652\n",
      "Epoch 86/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.5860 - accuracy: 0.8665 - val_loss: 5.1025 - val_accuracy: 0.7900\n",
      "Epoch 87/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.6614 - accuracy: 0.8682 - val_loss: 5.1603 - val_accuracy: 0.7749\n",
      "Epoch 88/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.6959 - accuracy: 0.8514 - val_loss: 5.2901 - val_accuracy: 0.7638\n",
      "Epoch 89/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.6530 - accuracy: 0.8573 - val_loss: 5.5583 - val_accuracy: 0.7693\n",
      "Epoch 90/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.7584 - accuracy: 0.8573 - val_loss: 5.2848 - val_accuracy: 0.7788\n",
      "Epoch 91/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.7003 - accuracy: 0.8604 - val_loss: 5.5936 - val_accuracy: 0.7779\n",
      "Epoch 92/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.7222 - accuracy: 0.8577 - val_loss: 5.4231 - val_accuracy: 0.7754\n",
      "Epoch 93/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.7808 - accuracy: 0.8606 - val_loss: 5.4800 - val_accuracy: 0.7812\n",
      "Epoch 94/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.6892 - accuracy: 0.8598 - val_loss: 5.5656 - val_accuracy: 0.7582\n",
      "Epoch 95/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.6841 - accuracy: 0.8504 - val_loss: 5.4305 - val_accuracy: 0.7674\n",
      "Epoch 96/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.6837 - accuracy: 0.8605 - val_loss: 5.6228 - val_accuracy: 0.7760\n",
      "Epoch 97/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.7231 - accuracy: 0.8621 - val_loss: 5.6801 - val_accuracy: 0.7687\n",
      "Epoch 98/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.8150 - accuracy: 0.8510 - val_loss: 5.7944 - val_accuracy: 0.7556\n",
      "Epoch 99/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.7353 - accuracy: 0.8594 - val_loss: 5.5603 - val_accuracy: 0.7837\n",
      "Epoch 100/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.8327 - accuracy: 0.8624 - val_loss: 5.5770 - val_accuracy: 0.7869\n",
      "Epoch 101/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.7583 - accuracy: 0.8579 - val_loss: 5.6666 - val_accuracy: 0.7652\n",
      "Epoch 102/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.7004 - accuracy: 0.8587 - val_loss: 5.8048 - val_accuracy: 0.7706\n",
      "Epoch 103/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.7247 - accuracy: 0.8618 - val_loss: 5.7607 - val_accuracy: 0.7762\n",
      "Epoch 104/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.6723 - accuracy: 0.8603 - val_loss: 5.9351 - val_accuracy: 0.7614\n",
      "Epoch 105/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.7457 - accuracy: 0.8531 - val_loss: 5.6992 - val_accuracy: 0.7736\n",
      "Epoch 106/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.6614 - accuracy: 0.8651 - val_loss: 5.8998 - val_accuracy: 0.7721\n",
      "Epoch 107/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.7268 - accuracy: 0.8588 - val_loss: 5.8638 - val_accuracy: 0.7726\n",
      "Epoch 108/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.8955 - accuracy: 0.8515 - val_loss: 5.7700 - val_accuracy: 0.7749\n",
      "Epoch 109/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.7595 - accuracy: 0.8618 - val_loss: 5.8427 - val_accuracy: 0.7734\n",
      "Epoch 110/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.8671 - accuracy: 0.8569 - val_loss: 5.8803 - val_accuracy: 0.7676\n",
      "Epoch 111/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.8346 - accuracy: 0.8533 - val_loss: 6.0210 - val_accuracy: 0.7612\n",
      "Epoch 112/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.8023 - accuracy: 0.8603 - val_loss: 6.0570 - val_accuracy: 0.7717\n",
      "Epoch 113/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.8900 - accuracy: 0.8592 - val_loss: 6.0428 - val_accuracy: 0.7698\n",
      "Epoch 114/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.8055 - accuracy: 0.8554 - val_loss: 6.1711 - val_accuracy: 0.7629\n",
      "Epoch 115/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.8902 - accuracy: 0.8545 - val_loss: 6.0283 - val_accuracy: 0.7766\n",
      "Epoch 116/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.8104 - accuracy: 0.8609 - val_loss: 6.3360 - val_accuracy: 0.7682\n",
      "Epoch 117/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.8878 - accuracy: 0.8566 - val_loss: 6.3123 - val_accuracy: 0.7657\n",
      "Epoch 118/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.8424 - accuracy: 0.8538 - val_loss: 6.0783 - val_accuracy: 0.7777\n",
      "Epoch 119/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.7993 - accuracy: 0.8668 - val_loss: 6.0450 - val_accuracy: 0.7833\n",
      "Epoch 120/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.9243 - accuracy: 0.8605 - val_loss: 6.0835 - val_accuracy: 0.7700\n",
      "Epoch 121/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.8668 - accuracy: 0.8473 - val_loss: 6.1946 - val_accuracy: 0.7640\n",
      "Epoch 122/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.8736 - accuracy: 0.8535 - val_loss: 6.5094 - val_accuracy: 0.7571\n",
      "Epoch 123/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.0851 - accuracy: 0.8550 - val_loss: 6.5539 - val_accuracy: 0.7674\n",
      "Epoch 124/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.9646 - accuracy: 0.8527 - val_loss: 6.2495 - val_accuracy: 0.7614\n",
      "Epoch 125/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.0008 - accuracy: 0.8461 - val_loss: 6.2113 - val_accuracy: 0.7674\n",
      "Epoch 126/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 1.9392 - accuracy: 0.8637 - val_loss: 6.3431 - val_accuracy: 0.7880\n",
      "Epoch 127/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.0407 - accuracy: 0.8611 - val_loss: 6.5469 - val_accuracy: 0.7740\n",
      "Epoch 128/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.1541 - accuracy: 0.8485 - val_loss: 6.5018 - val_accuracy: 0.7610\n",
      "Epoch 129/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.1342 - accuracy: 0.8528 - val_loss: 6.2402 - val_accuracy: 0.7850\n",
      "Epoch 130/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.1532 - accuracy: 0.8589 - val_loss: 6.8718 - val_accuracy: 0.7758\n",
      "Epoch 131/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.2730 - accuracy: 0.8501 - val_loss: 6.6775 - val_accuracy: 0.7653\n",
      "Epoch 132/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.2509 - accuracy: 0.8425 - val_loss: 6.6986 - val_accuracy: 0.7575\n",
      "Epoch 133/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.1656 - accuracy: 0.8514 - val_loss: 6.9013 - val_accuracy: 0.7768\n",
      "Epoch 134/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.2791 - accuracy: 0.8581 - val_loss: 6.8392 - val_accuracy: 0.7799\n",
      "Epoch 135/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.2615 - accuracy: 0.8542 - val_loss: 6.4750 - val_accuracy: 0.7725\n",
      "Epoch 136/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.1496 - accuracy: 0.8537 - val_loss: 6.4402 - val_accuracy: 0.7777\n",
      "Epoch 137/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.1207 - accuracy: 0.8589 - val_loss: 6.6244 - val_accuracy: 0.7743\n",
      "Epoch 138/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.1086 - accuracy: 0.8571 - val_loss: 6.6981 - val_accuracy: 0.7784\n",
      "Epoch 139/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.1646 - accuracy: 0.8479 - val_loss: 6.7670 - val_accuracy: 0.7667\n",
      "Epoch 140/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.1209 - accuracy: 0.8517 - val_loss: 7.0331 - val_accuracy: 0.7711\n",
      "Epoch 141/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.2998 - accuracy: 0.8563 - val_loss: 6.8600 - val_accuracy: 0.7771\n",
      "Epoch 142/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.3488 - accuracy: 0.8539 - val_loss: 6.5657 - val_accuracy: 0.7743\n",
      "Epoch 143/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.3266 - accuracy: 0.8496 - val_loss: 6.7323 - val_accuracy: 0.7754\n",
      "Epoch 144/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.2625 - accuracy: 0.8570 - val_loss: 6.7232 - val_accuracy: 0.7753\n",
      "Epoch 145/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.5009 - accuracy: 0.8452 - val_loss: 7.1650 - val_accuracy: 0.7708\n",
      "Epoch 146/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.2836 - accuracy: 0.8463 - val_loss: 7.4029 - val_accuracy: 0.7506\n",
      "Epoch 147/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.2213 - accuracy: 0.8525 - val_loss: 6.9489 - val_accuracy: 0.7747\n",
      "Epoch 148/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.3345 - accuracy: 0.8576 - val_loss: 6.8236 - val_accuracy: 0.7762\n",
      "Epoch 149/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.4054 - accuracy: 0.8499 - val_loss: 7.0126 - val_accuracy: 0.7569\n",
      "Epoch 150/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.2681 - accuracy: 0.8520 - val_loss: 7.4842 - val_accuracy: 0.7519\n",
      "Epoch 151/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.5240 - accuracy: 0.8495 - val_loss: 7.0771 - val_accuracy: 0.7702\n",
      "Epoch 152/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.5798 - accuracy: 0.8529 - val_loss: 7.3516 - val_accuracy: 0.7698\n",
      "Epoch 153/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.4629 - accuracy: 0.8501 - val_loss: 7.1990 - val_accuracy: 0.7640\n",
      "Epoch 154/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.3609 - accuracy: 0.8467 - val_loss: 6.8167 - val_accuracy: 0.7689\n",
      "Epoch 155/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.1954 - accuracy: 0.8616 - val_loss: 7.0755 - val_accuracy: 0.7766\n",
      "Epoch 156/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.2984 - accuracy: 0.8622 - val_loss: 6.9079 - val_accuracy: 0.7740\n",
      "Epoch 157/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.3444 - accuracy: 0.8531 - val_loss: 7.1282 - val_accuracy: 0.7682\n",
      "Epoch 158/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.1867 - accuracy: 0.8560 - val_loss: 7.0242 - val_accuracy: 0.7768\n",
      "Epoch 159/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.2466 - accuracy: 0.8530 - val_loss: 7.0950 - val_accuracy: 0.7667\n",
      "Epoch 160/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.3762 - accuracy: 0.8500 - val_loss: 7.4960 - val_accuracy: 0.7494\n",
      "Epoch 161/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.2924 - accuracy: 0.8473 - val_loss: 7.2649 - val_accuracy: 0.7478\n",
      "Epoch 162/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.1770 - accuracy: 0.8566 - val_loss: 6.9133 - val_accuracy: 0.7799\n",
      "Epoch 163/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.2517 - accuracy: 0.8603 - val_loss: 7.4188 - val_accuracy: 0.7698\n",
      "Epoch 164/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.4045 - accuracy: 0.8502 - val_loss: 7.4265 - val_accuracy: 0.7637\n",
      "Epoch 165/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.4305 - accuracy: 0.8508 - val_loss: 7.0400 - val_accuracy: 0.7736\n",
      "Epoch 166/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.4033 - accuracy: 0.8563 - val_loss: 7.6715 - val_accuracy: 0.7515\n",
      "Epoch 167/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.6334 - accuracy: 0.8521 - val_loss: 7.8789 - val_accuracy: 0.7541\n",
      "Epoch 168/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.8312 - accuracy: 0.8406 - val_loss: 7.5169 - val_accuracy: 0.7605\n",
      "Epoch 169/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.7259 - accuracy: 0.8434 - val_loss: 7.4367 - val_accuracy: 0.7743\n",
      "Epoch 170/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.7885 - accuracy: 0.8490 - val_loss: 7.2230 - val_accuracy: 0.7842\n",
      "Epoch 171/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.8358 - accuracy: 0.8459 - val_loss: 7.5371 - val_accuracy: 0.7771\n",
      "Epoch 172/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.8294 - accuracy: 0.8441 - val_loss: 7.6359 - val_accuracy: 0.7831\n",
      "Epoch 173/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.8237 - accuracy: 0.8515 - val_loss: 7.3340 - val_accuracy: 0.7857\n",
      "Epoch 174/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.7107 - accuracy: 0.8463 - val_loss: 7.7581 - val_accuracy: 0.7653\n",
      "Epoch 175/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.8249 - accuracy: 0.8445 - val_loss: 7.6150 - val_accuracy: 0.7670\n",
      "Epoch 176/1000\n",
      "1069/1069 [==============================] - 1s 994us/step - loss: 2.7418 - accuracy: 0.8481 - val_loss: 7.7120 - val_accuracy: 0.7603\n",
      "Epoch 177/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.7942 - accuracy: 0.8532 - val_loss: 7.4616 - val_accuracy: 0.7663\n",
      "Epoch 178/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.8839 - accuracy: 0.8503 - val_loss: 7.8937 - val_accuracy: 0.7624\n",
      "Epoch 179/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.9208 - accuracy: 0.8462 - val_loss: 7.8232 - val_accuracy: 0.7610\n",
      "Epoch 180/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.1419 - accuracy: 0.8436 - val_loss: 7.4053 - val_accuracy: 0.7756\n",
      "Epoch 181/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.8993 - accuracy: 0.8533 - val_loss: 7.2978 - val_accuracy: 0.7837\n",
      "Epoch 182/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.8373 - accuracy: 0.8488 - val_loss: 7.7468 - val_accuracy: 0.7783\n",
      "Epoch 183/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.9823 - accuracy: 0.8462 - val_loss: 8.1880 - val_accuracy: 0.7874\n",
      "Epoch 184/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.2113 - accuracy: 0.8476 - val_loss: 7.8958 - val_accuracy: 0.7940\n",
      "Epoch 185/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.1318 - accuracy: 0.8503 - val_loss: 7.7802 - val_accuracy: 0.7844\n",
      "Epoch 186/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.9195 - accuracy: 0.8508 - val_loss: 8.1091 - val_accuracy: 0.7741\n",
      "Epoch 187/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.9492 - accuracy: 0.8494 - val_loss: 8.1815 - val_accuracy: 0.7743\n",
      "Epoch 188/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.1634 - accuracy: 0.8374 - val_loss: 7.7059 - val_accuracy: 0.7865\n",
      "Epoch 189/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.1248 - accuracy: 0.8504 - val_loss: 8.1546 - val_accuracy: 0.7798\n",
      "Epoch 190/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.8613 - accuracy: 0.8561 - val_loss: 7.6584 - val_accuracy: 0.7818\n",
      "Epoch 191/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.8596 - accuracy: 0.8425 - val_loss: 7.9863 - val_accuracy: 0.7700\n",
      "Epoch 192/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.0355 - accuracy: 0.8467 - val_loss: 7.8738 - val_accuracy: 0.7801\n",
      "Epoch 193/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.9508 - accuracy: 0.8504 - val_loss: 8.1049 - val_accuracy: 0.7668\n",
      "Epoch 194/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.9096 - accuracy: 0.8535 - val_loss: 7.5378 - val_accuracy: 0.7801\n",
      "Epoch 195/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.0345 - accuracy: 0.8482 - val_loss: 8.3029 - val_accuracy: 0.7667\n",
      "Epoch 196/1000\n",
      "1069/1069 [==============================] - 1s 951us/step - loss: 2.9488 - accuracy: 0.8471 - val_loss: 7.8693 - val_accuracy: 0.7721\n",
      "Epoch 197/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.0026 - accuracy: 0.8532 - val_loss: 8.3015 - val_accuracy: 0.7702\n",
      "Epoch 198/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.8588 - accuracy: 0.8564 - val_loss: 7.5229 - val_accuracy: 0.7811\n",
      "Epoch 199/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.8445 - accuracy: 0.8486 - val_loss: 8.4461 - val_accuracy: 0.7569\n",
      "Epoch 200/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.7512 - accuracy: 0.8525 - val_loss: 7.8597 - val_accuracy: 0.7786\n",
      "Epoch 201/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.8392 - accuracy: 0.8559 - val_loss: 8.2875 - val_accuracy: 0.7637\n",
      "Epoch 202/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.0113 - accuracy: 0.8489 - val_loss: 7.9194 - val_accuracy: 0.7771\n",
      "Epoch 203/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.9149 - accuracy: 0.8463 - val_loss: 8.8105 - val_accuracy: 0.7588\n",
      "Epoch 204/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.9960 - accuracy: 0.8459 - val_loss: 7.8240 - val_accuracy: 0.7792\n",
      "Epoch 205/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.0010 - accuracy: 0.8526 - val_loss: 8.2935 - val_accuracy: 0.7734\n",
      "Epoch 206/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.1330 - accuracy: 0.8505 - val_loss: 8.3331 - val_accuracy: 0.7809\n",
      "Epoch 207/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.8685 - accuracy: 0.8567 - val_loss: 8.1269 - val_accuracy: 0.7723\n",
      "Epoch 208/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.9855 - accuracy: 0.8508 - val_loss: 8.4120 - val_accuracy: 0.7638\n",
      "Epoch 209/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.9463 - accuracy: 0.8535 - val_loss: 8.2719 - val_accuracy: 0.7646\n",
      "Epoch 210/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.9874 - accuracy: 0.8470 - val_loss: 8.6880 - val_accuracy: 0.7571\n",
      "Epoch 211/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.8942 - accuracy: 0.8475 - val_loss: 8.4805 - val_accuracy: 0.7659\n",
      "Epoch 212/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.1341 - accuracy: 0.8407 - val_loss: 8.2796 - val_accuracy: 0.7582\n",
      "Epoch 213/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 2.8843 - accuracy: 0.8543 - val_loss: 7.7576 - val_accuracy: 0.7848\n",
      "Epoch 214/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.1884 - accuracy: 0.8525 - val_loss: 8.8956 - val_accuracy: 0.7706\n",
      "Epoch 215/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.0870 - accuracy: 0.8509 - val_loss: 7.7013 - val_accuracy: 0.7747\n",
      "Epoch 216/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.2668 - accuracy: 0.8471 - val_loss: 8.5444 - val_accuracy: 0.7580\n",
      "Epoch 217/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.3379 - accuracy: 0.8478 - val_loss: 8.2724 - val_accuracy: 0.7799\n",
      "Epoch 218/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.0721 - accuracy: 0.8503 - val_loss: 8.1512 - val_accuracy: 0.7775\n",
      "Epoch 219/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.3251 - accuracy: 0.8422 - val_loss: 8.8603 - val_accuracy: 0.7560\n",
      "Epoch 220/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.1546 - accuracy: 0.8437 - val_loss: 8.1818 - val_accuracy: 0.7775\n",
      "Epoch 221/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.5419 - accuracy: 0.8379 - val_loss: 9.9335 - val_accuracy: 0.7590\n",
      "Epoch 222/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.5393 - accuracy: 0.8428 - val_loss: 8.0325 - val_accuracy: 0.7929\n",
      "Epoch 223/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.5592 - accuracy: 0.8457 - val_loss: 9.1978 - val_accuracy: 0.7513\n",
      "Epoch 224/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.7310 - accuracy: 0.8376 - val_loss: 8.9908 - val_accuracy: 0.7784\n",
      "Epoch 225/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.4357 - accuracy: 0.8480 - val_loss: 8.2454 - val_accuracy: 0.7942\n",
      "Epoch 226/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.8154 - accuracy: 0.8445 - val_loss: 9.4048 - val_accuracy: 0.7674\n",
      "Epoch 227/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.9909 - accuracy: 0.8430 - val_loss: 9.4748 - val_accuracy: 0.7745\n",
      "Epoch 228/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.6943 - accuracy: 0.8417 - val_loss: 7.9228 - val_accuracy: 0.7912\n",
      "Epoch 229/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.6973 - accuracy: 0.8425 - val_loss: 9.0266 - val_accuracy: 0.7764\n",
      "Epoch 230/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.0811 - accuracy: 0.8433 - val_loss: 9.7508 - val_accuracy: 0.7786\n",
      "Epoch 231/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.7328 - accuracy: 0.8493 - val_loss: 8.2841 - val_accuracy: 0.7949\n",
      "Epoch 232/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.5268 - accuracy: 0.8488 - val_loss: 8.5885 - val_accuracy: 0.7812\n",
      "Epoch 233/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.8792 - accuracy: 0.8368 - val_loss: 10.4594 - val_accuracy: 0.7545\n",
      "Epoch 234/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.0108 - accuracy: 0.8394 - val_loss: 8.8307 - val_accuracy: 0.7801\n",
      "Epoch 235/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.7594 - accuracy: 0.8460 - val_loss: 8.4597 - val_accuracy: 0.7842\n",
      "Epoch 236/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.8800 - accuracy: 0.8382 - val_loss: 10.5002 - val_accuracy: 0.7584\n",
      "Epoch 237/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.0791 - accuracy: 0.8327 - val_loss: 8.9414 - val_accuracy: 0.7642\n",
      "Epoch 238/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.5899 - accuracy: 0.8480 - val_loss: 8.3420 - val_accuracy: 0.7889\n",
      "Epoch 239/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.9301 - accuracy: 0.8472 - val_loss: 10.3943 - val_accuracy: 0.7743\n",
      "Epoch 240/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.0983 - accuracy: 0.8489 - val_loss: 9.7611 - val_accuracy: 0.7646\n",
      "Epoch 241/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.9488 - accuracy: 0.8432 - val_loss: 8.8773 - val_accuracy: 0.7861\n",
      "Epoch 242/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.8817 - accuracy: 0.8402 - val_loss: 8.8518 - val_accuracy: 0.7799\n",
      "Epoch 243/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.9607 - accuracy: 0.8435 - val_loss: 9.7217 - val_accuracy: 0.7672\n",
      "Epoch 244/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.1445 - accuracy: 0.8430 - val_loss: 10.0299 - val_accuracy: 0.7711\n",
      "Epoch 245/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.7794 - accuracy: 0.8426 - val_loss: 8.4741 - val_accuracy: 0.7852\n",
      "Epoch 246/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.6876 - accuracy: 0.8420 - val_loss: 9.3440 - val_accuracy: 0.7633\n",
      "Epoch 247/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.8070 - accuracy: 0.8384 - val_loss: 9.3146 - val_accuracy: 0.7771\n",
      "Epoch 248/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.6760 - accuracy: 0.8510 - val_loss: 8.5886 - val_accuracy: 0.8003\n",
      "Epoch 249/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.7784 - accuracy: 0.8539 - val_loss: 9.4548 - val_accuracy: 0.7807\n",
      "Epoch 250/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.9688 - accuracy: 0.8395 - val_loss: 10.2414 - val_accuracy: 0.7614\n",
      "Epoch 251/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.8995 - accuracy: 0.8365 - val_loss: 8.8350 - val_accuracy: 0.7951\n",
      "Epoch 252/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.9127 - accuracy: 0.8549 - val_loss: 9.1100 - val_accuracy: 0.7921\n",
      "Epoch 253/1000\n",
      "1069/1069 [==============================] - 1s 1000us/step - loss: 4.0514 - accuracy: 0.8525 - val_loss: 10.3834 - val_accuracy: 0.7788\n",
      "Epoch 254/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.9788 - accuracy: 0.8484 - val_loss: 9.7669 - val_accuracy: 0.7522\n",
      "Epoch 255/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.8540 - accuracy: 0.8430 - val_loss: 9.3447 - val_accuracy: 0.7653\n",
      "Epoch 256/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.6457 - accuracy: 0.8412 - val_loss: 9.1144 - val_accuracy: 0.7700\n",
      "Epoch 257/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.7462 - accuracy: 0.8474 - val_loss: 9.6423 - val_accuracy: 0.7745\n",
      "Epoch 258/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.8720 - accuracy: 0.8546 - val_loss: 9.7013 - val_accuracy: 0.7842\n",
      "Epoch 259/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.7028 - accuracy: 0.8490 - val_loss: 8.8504 - val_accuracy: 0.7749\n",
      "Epoch 260/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.9053 - accuracy: 0.8399 - val_loss: 9.7969 - val_accuracy: 0.7588\n",
      "Epoch 261/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.0271 - accuracy: 0.8467 - val_loss: 10.5901 - val_accuracy: 0.7775\n",
      "Epoch 262/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.0982 - accuracy: 0.8523 - val_loss: 9.4769 - val_accuracy: 0.7754\n",
      "Epoch 263/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.8903 - accuracy: 0.8522 - val_loss: 8.8083 - val_accuracy: 0.7874\n",
      "Epoch 264/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.6738 - accuracy: 0.8483 - val_loss: 10.0949 - val_accuracy: 0.7625\n",
      "Epoch 265/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.1145 - accuracy: 0.8370 - val_loss: 10.0947 - val_accuracy: 0.7519\n",
      "Epoch 266/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.9582 - accuracy: 0.8436 - val_loss: 9.8005 - val_accuracy: 0.7827\n",
      "Epoch 267/1000\n",
      "1069/1069 [==============================] - 1s 993us/step - loss: 3.9961 - accuracy: 0.8521 - val_loss: 9.2206 - val_accuracy: 0.7955\n",
      "Epoch 268/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.8396 - accuracy: 0.8531 - val_loss: 9.4882 - val_accuracy: 0.7811\n",
      "Epoch 269/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.0235 - accuracy: 0.8376 - val_loss: 10.7433 - val_accuracy: 0.7565\n",
      "Epoch 270/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.8931 - accuracy: 0.8402 - val_loss: 9.1323 - val_accuracy: 0.7899\n",
      "Epoch 271/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.9121 - accuracy: 0.8577 - val_loss: 9.6145 - val_accuracy: 0.7921\n",
      "Epoch 272/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.2409 - accuracy: 0.8499 - val_loss: 10.4365 - val_accuracy: 0.7798\n",
      "Epoch 273/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.1231 - accuracy: 0.8421 - val_loss: 9.8986 - val_accuracy: 0.7592\n",
      "Epoch 274/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.0296 - accuracy: 0.8413 - val_loss: 10.0608 - val_accuracy: 0.7586\n",
      "Epoch 275/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.9014 - accuracy: 0.8424 - val_loss: 10.2877 - val_accuracy: 0.7624\n",
      "Epoch 276/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.2191 - accuracy: 0.8426 - val_loss: 10.5193 - val_accuracy: 0.7590\n",
      "Epoch 277/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.0602 - accuracy: 0.8547 - val_loss: 10.3386 - val_accuracy: 0.7867\n",
      "Epoch 278/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.9652 - accuracy: 0.8539 - val_loss: 9.3854 - val_accuracy: 0.7818\n",
      "Epoch 279/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.3184 - accuracy: 0.8388 - val_loss: 9.8158 - val_accuracy: 0.7738\n",
      "Epoch 280/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.8544 - accuracy: 0.8526 - val_loss: 10.1113 - val_accuracy: 0.7943\n",
      "Epoch 281/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.0941 - accuracy: 0.8559 - val_loss: 10.0595 - val_accuracy: 0.7966\n",
      "Epoch 282/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.1331 - accuracy: 0.8481 - val_loss: 10.0557 - val_accuracy: 0.7796\n",
      "Epoch 283/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.1451 - accuracy: 0.8384 - val_loss: 10.2180 - val_accuracy: 0.7760\n",
      "Epoch 284/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.1891 - accuracy: 0.8415 - val_loss: 9.4880 - val_accuracy: 0.7839\n",
      "Epoch 285/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.7107 - accuracy: 0.8538 - val_loss: 10.2000 - val_accuracy: 0.7620\n",
      "Epoch 286/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.1484 - accuracy: 0.8451 - val_loss: 10.4761 - val_accuracy: 0.7655\n",
      "Epoch 287/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.0855 - accuracy: 0.8495 - val_loss: 10.5450 - val_accuracy: 0.7601\n",
      "Epoch 288/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.9937 - accuracy: 0.8450 - val_loss: 10.1030 - val_accuracy: 0.7622\n",
      "Epoch 289/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.0885 - accuracy: 0.8445 - val_loss: 9.8274 - val_accuracy: 0.7835\n",
      "Epoch 290/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.2151 - accuracy: 0.8514 - val_loss: 10.7115 - val_accuracy: 0.7754\n",
      "Epoch 291/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.1319 - accuracy: 0.8538 - val_loss: 10.3694 - val_accuracy: 0.7783\n",
      "Epoch 292/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.1196 - accuracy: 0.8390 - val_loss: 9.8115 - val_accuracy: 0.7784\n",
      "Epoch 293/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 3.9797 - accuracy: 0.8510 - val_loss: 10.8350 - val_accuracy: 0.7638\n",
      "Epoch 294/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.4379 - accuracy: 0.8490 - val_loss: 10.7608 - val_accuracy: 0.7728\n",
      "Epoch 295/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.2193 - accuracy: 0.8500 - val_loss: 10.3061 - val_accuracy: 0.7715\n",
      "Epoch 296/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.1862 - accuracy: 0.8495 - val_loss: 9.6388 - val_accuracy: 0.7874\n",
      "Epoch 297/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.6393 - accuracy: 0.8395 - val_loss: 11.2372 - val_accuracy: 0.7704\n",
      "Epoch 298/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.6005 - accuracy: 0.8352 - val_loss: 10.5223 - val_accuracy: 0.7854\n",
      "Epoch 299/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.4535 - accuracy: 0.8439 - val_loss: 9.9857 - val_accuracy: 0.8030\n",
      "Epoch 300/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.8092 - accuracy: 0.8487 - val_loss: 10.9425 - val_accuracy: 0.7964\n",
      "Epoch 301/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.0161 - accuracy: 0.8459 - val_loss: 11.5178 - val_accuracy: 0.7429\n",
      "Epoch 302/1000\n",
      "1069/1069 [==============================] - 1s 974us/step - loss: 4.8509 - accuracy: 0.8350 - val_loss: 12.0763 - val_accuracy: 0.7416\n",
      "Epoch 303/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.7270 - accuracy: 0.8341 - val_loss: 10.4345 - val_accuracy: 0.7702\n",
      "Epoch 304/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.8706 - accuracy: 0.8422 - val_loss: 9.9750 - val_accuracy: 0.7929\n",
      "Epoch 305/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.0878 - accuracy: 0.8409 - val_loss: 11.9890 - val_accuracy: 0.7803\n",
      "Epoch 306/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.0490 - accuracy: 0.8416 - val_loss: 11.5578 - val_accuracy: 0.7728\n",
      "Epoch 307/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.0410 - accuracy: 0.8396 - val_loss: 11.2925 - val_accuracy: 0.7726\n",
      "Epoch 308/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.8352 - accuracy: 0.8305 - val_loss: 9.9374 - val_accuracy: 0.7831\n",
      "Epoch 309/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.6960 - accuracy: 0.8411 - val_loss: 11.0245 - val_accuracy: 0.7655\n",
      "Epoch 310/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.9695 - accuracy: 0.8495 - val_loss: 12.1737 - val_accuracy: 0.7822\n",
      "Epoch 311/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.9325 - accuracy: 0.8379 - val_loss: 12.8121 - val_accuracy: 0.7704\n",
      "Epoch 312/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.1650 - accuracy: 0.8435 - val_loss: 11.5066 - val_accuracy: 0.7781\n",
      "Epoch 313/1000\n",
      "1069/1069 [==============================] - 1s 996us/step - loss: 5.5372 - accuracy: 0.8253 - val_loss: 9.8847 - val_accuracy: 0.7874\n",
      "Epoch 314/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.2397 - accuracy: 0.8429 - val_loss: 12.2294 - val_accuracy: 0.7605\n",
      "Epoch 315/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.1510 - accuracy: 0.8486 - val_loss: 11.1055 - val_accuracy: 0.7839\n",
      "Epoch 316/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.7692 - accuracy: 0.8359 - val_loss: 11.8512 - val_accuracy: 0.7899\n",
      "Epoch 317/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.1572 - accuracy: 0.8376 - val_loss: 12.2584 - val_accuracy: 0.7852\n",
      "Epoch 318/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.3663 - accuracy: 0.8328 - val_loss: 10.8655 - val_accuracy: 0.7831\n",
      "Epoch 319/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.2808 - accuracy: 0.8333 - val_loss: 11.9212 - val_accuracy: 0.7464\n",
      "Epoch 320/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.4936 - accuracy: 0.8371 - val_loss: 12.6890 - val_accuracy: 0.7573\n",
      "Epoch 321/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.3720 - accuracy: 0.8490 - val_loss: 11.5473 - val_accuracy: 0.7949\n",
      "Epoch 322/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.8200 - accuracy: 0.8475 - val_loss: 12.6983 - val_accuracy: 0.7912\n",
      "Epoch 323/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.4563 - accuracy: 0.8410 - val_loss: 11.7906 - val_accuracy: 0.7706\n",
      "Epoch 324/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.2096 - accuracy: 0.8427 - val_loss: 11.1826 - val_accuracy: 0.7713\n",
      "Epoch 325/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.9400 - accuracy: 0.8467 - val_loss: 11.4590 - val_accuracy: 0.7807\n",
      "Epoch 326/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.1188 - accuracy: 0.8474 - val_loss: 12.0675 - val_accuracy: 0.7781\n",
      "Epoch 327/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.6296 - accuracy: 0.8321 - val_loss: 13.0297 - val_accuracy: 0.7715\n",
      "Epoch 328/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.5796 - accuracy: 0.8389 - val_loss: 13.0889 - val_accuracy: 0.7513\n",
      "Epoch 329/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.5677 - accuracy: 0.8419 - val_loss: 12.2145 - val_accuracy: 0.7723\n",
      "Epoch 330/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.0959 - accuracy: 0.8461 - val_loss: 10.9429 - val_accuracy: 0.7891\n",
      "Epoch 331/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.3786 - accuracy: 0.8423 - val_loss: 11.6327 - val_accuracy: 0.7977\n",
      "Epoch 332/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.5749 - accuracy: 0.8405 - val_loss: 11.7607 - val_accuracy: 0.7930\n",
      "Epoch 333/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.4823 - accuracy: 0.8516 - val_loss: 11.8586 - val_accuracy: 0.7781\n",
      "Epoch 334/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.4514 - accuracy: 0.8482 - val_loss: 13.7770 - val_accuracy: 0.7517\n",
      "Epoch 335/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.7719 - accuracy: 0.8394 - val_loss: 12.5819 - val_accuracy: 0.7762\n",
      "Epoch 336/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.4275 - accuracy: 0.8492 - val_loss: 13.0722 - val_accuracy: 0.7899\n",
      "Epoch 337/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.3774 - accuracy: 0.8433 - val_loss: 12.0714 - val_accuracy: 0.7865\n",
      "Epoch 338/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.4546 - accuracy: 0.8384 - val_loss: 11.7264 - val_accuracy: 0.7794\n",
      "Epoch 339/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.0775 - accuracy: 0.8444 - val_loss: 12.0768 - val_accuracy: 0.7723\n",
      "Epoch 340/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.2352 - accuracy: 0.8480 - val_loss: 12.2510 - val_accuracy: 0.7756\n",
      "Epoch 341/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.1016 - accuracy: 0.8493 - val_loss: 12.8805 - val_accuracy: 0.7863\n",
      "Epoch 342/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.2319 - accuracy: 0.8501 - val_loss: 12.8518 - val_accuracy: 0.7719\n",
      "Epoch 343/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.5876 - accuracy: 0.8465 - val_loss: 13.5834 - val_accuracy: 0.7721\n",
      "Epoch 344/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.2653 - accuracy: 0.8472 - val_loss: 12.4826 - val_accuracy: 0.7665\n",
      "Epoch 345/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.8800 - accuracy: 0.8523 - val_loss: 12.4724 - val_accuracy: 0.7713\n",
      "Epoch 346/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.1491 - accuracy: 0.8456 - val_loss: 11.6179 - val_accuracy: 0.7871\n",
      "Epoch 347/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.0924 - accuracy: 0.8543 - val_loss: 12.2133 - val_accuracy: 0.7831\n",
      "Epoch 348/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.8927 - accuracy: 0.8545 - val_loss: 11.7663 - val_accuracy: 0.7805\n",
      "Epoch 349/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.8391 - accuracy: 0.8442 - val_loss: 12.3260 - val_accuracy: 0.7532\n",
      "Epoch 350/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.0232 - accuracy: 0.8360 - val_loss: 12.6801 - val_accuracy: 0.7743\n",
      "Epoch 351/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.3102 - accuracy: 0.8416 - val_loss: 11.9842 - val_accuracy: 0.7891\n",
      "Epoch 352/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.6763 - accuracy: 0.8571 - val_loss: 11.5247 - val_accuracy: 0.7829\n",
      "Epoch 353/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.2125 - accuracy: 0.8491 - val_loss: 12.2993 - val_accuracy: 0.7753\n",
      "Epoch 354/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.9685 - accuracy: 0.8595 - val_loss: 12.7761 - val_accuracy: 0.7745\n",
      "Epoch 355/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.6307 - accuracy: 0.8392 - val_loss: 12.8524 - val_accuracy: 0.7721\n",
      "Epoch 356/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.0275 - accuracy: 0.8388 - val_loss: 12.2661 - val_accuracy: 0.7717\n",
      "Epoch 357/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 4.7010 - accuracy: 0.8531 - val_loss: 11.7558 - val_accuracy: 0.7973\n",
      "Epoch 358/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.5483 - accuracy: 0.8480 - val_loss: 12.7792 - val_accuracy: 0.7871\n",
      "Epoch 359/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.5056 - accuracy: 0.8540 - val_loss: 12.2506 - val_accuracy: 0.7687\n",
      "Epoch 360/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.5713 - accuracy: 0.8348 - val_loss: 12.9234 - val_accuracy: 0.7708\n",
      "Epoch 361/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.1706 - accuracy: 0.8395 - val_loss: 13.2811 - val_accuracy: 0.7659\n",
      "Epoch 362/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.7134 - accuracy: 0.8432 - val_loss: 13.5470 - val_accuracy: 0.7710\n",
      "Epoch 363/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.5821 - accuracy: 0.8466 - val_loss: 13.1150 - val_accuracy: 0.7717\n",
      "Epoch 364/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.7432 - accuracy: 0.8488 - val_loss: 12.4071 - val_accuracy: 0.7900\n",
      "Epoch 365/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.2624 - accuracy: 0.8535 - val_loss: 12.1953 - val_accuracy: 0.7887\n",
      "Epoch 366/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.8950 - accuracy: 0.8481 - val_loss: 12.2765 - val_accuracy: 0.7820\n",
      "Epoch 367/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.7519 - accuracy: 0.8321 - val_loss: 12.3161 - val_accuracy: 0.7745\n",
      "Epoch 368/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.4913 - accuracy: 0.8463 - val_loss: 12.1603 - val_accuracy: 0.7818\n",
      "Epoch 369/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.5885 - accuracy: 0.8473 - val_loss: 14.0563 - val_accuracy: 0.7792\n",
      "Epoch 370/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.3215 - accuracy: 0.8402 - val_loss: 14.2088 - val_accuracy: 0.7633\n",
      "Epoch 371/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.4145 - accuracy: 0.8302 - val_loss: 15.3183 - val_accuracy: 0.7440\n",
      "Epoch 372/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.9822 - accuracy: 0.8349 - val_loss: 13.3280 - val_accuracy: 0.7665\n",
      "Epoch 373/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.7056 - accuracy: 0.8528 - val_loss: 14.3675 - val_accuracy: 0.7773\n",
      "Epoch 374/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.2259 - accuracy: 0.8461 - val_loss: 13.5807 - val_accuracy: 0.7818\n",
      "Epoch 375/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.2546 - accuracy: 0.8453 - val_loss: 14.2255 - val_accuracy: 0.7826\n",
      "Epoch 376/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.1104 - accuracy: 0.8490 - val_loss: 13.2689 - val_accuracy: 0.7839\n",
      "Epoch 377/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.8211 - accuracy: 0.8542 - val_loss: 13.7909 - val_accuracy: 0.7897\n",
      "Epoch 378/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.8234 - accuracy: 0.8423 - val_loss: 12.9928 - val_accuracy: 0.7871\n",
      "Epoch 379/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.8819 - accuracy: 0.8371 - val_loss: 13.1002 - val_accuracy: 0.7773\n",
      "Epoch 380/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.5809 - accuracy: 0.8412 - val_loss: 12.6178 - val_accuracy: 0.7887\n",
      "Epoch 381/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.3507 - accuracy: 0.8532 - val_loss: 12.6693 - val_accuracy: 0.7863\n",
      "Epoch 382/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.4361 - accuracy: 0.8470 - val_loss: 13.8670 - val_accuracy: 0.7644\n",
      "Epoch 383/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.1928 - accuracy: 0.8302 - val_loss: 14.0290 - val_accuracy: 0.7517\n",
      "Epoch 384/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.6672 - accuracy: 0.8385 - val_loss: 13.9124 - val_accuracy: 0.7725\n",
      "Epoch 385/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.3392 - accuracy: 0.8509 - val_loss: 12.7601 - val_accuracy: 0.7856\n",
      "Epoch 386/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.5129 - accuracy: 0.8508 - val_loss: 13.6013 - val_accuracy: 0.7726\n",
      "Epoch 387/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.1701 - accuracy: 0.8375 - val_loss: 13.2405 - val_accuracy: 0.7756\n",
      "Epoch 388/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.7141 - accuracy: 0.8526 - val_loss: 13.2644 - val_accuracy: 0.7861\n",
      "Epoch 389/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.4803 - accuracy: 0.8520 - val_loss: 12.5900 - val_accuracy: 0.7938\n",
      "Epoch 390/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.7277 - accuracy: 0.8471 - val_loss: 12.9833 - val_accuracy: 0.7820\n",
      "Epoch 391/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.9417 - accuracy: 0.8476 - val_loss: 13.4282 - val_accuracy: 0.7835\n",
      "Epoch 392/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.3132 - accuracy: 0.8507 - val_loss: 13.5715 - val_accuracy: 0.7812\n",
      "Epoch 393/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.8459 - accuracy: 0.8473 - val_loss: 13.2677 - val_accuracy: 0.7841\n",
      "Epoch 394/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.2475 - accuracy: 0.8254 - val_loss: 14.3638 - val_accuracy: 0.7605\n",
      "Epoch 395/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.9409 - accuracy: 0.8406 - val_loss: 14.2518 - val_accuracy: 0.7678\n",
      "Epoch 396/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.4734 - accuracy: 0.8433 - val_loss: 14.1311 - val_accuracy: 0.7702\n",
      "Epoch 397/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.4889 - accuracy: 0.8590 - val_loss: 12.6973 - val_accuracy: 0.7975\n",
      "Epoch 398/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.9234 - accuracy: 0.8369 - val_loss: 12.9328 - val_accuracy: 0.7826\n",
      "Epoch 399/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.4260 - accuracy: 0.8493 - val_loss: 13.4840 - val_accuracy: 0.7790\n",
      "Epoch 400/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.5579 - accuracy: 0.8364 - val_loss: 13.8676 - val_accuracy: 0.7846\n",
      "Epoch 401/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.4239 - accuracy: 0.8527 - val_loss: 13.3575 - val_accuracy: 0.7837\n",
      "Epoch 402/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.1179 - accuracy: 0.8429 - val_loss: 14.0634 - val_accuracy: 0.7897\n",
      "Epoch 403/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.8555 - accuracy: 0.8553 - val_loss: 14.6290 - val_accuracy: 0.7726\n",
      "Epoch 404/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.2475 - accuracy: 0.8495 - val_loss: 14.4771 - val_accuracy: 0.7743\n",
      "Epoch 405/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.5934 - accuracy: 0.8473 - val_loss: 13.9849 - val_accuracy: 0.7648\n",
      "Epoch 406/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.8049 - accuracy: 0.8372 - val_loss: 13.8987 - val_accuracy: 0.7794\n",
      "Epoch 407/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.4352 - accuracy: 0.8512 - val_loss: 14.0635 - val_accuracy: 0.7704\n",
      "Epoch 408/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.1143 - accuracy: 0.8540 - val_loss: 14.4731 - val_accuracy: 0.7732\n",
      "Epoch 409/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.9464 - accuracy: 0.8445 - val_loss: 14.0522 - val_accuracy: 0.7741\n",
      "Epoch 410/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.7607 - accuracy: 0.8402 - val_loss: 13.5988 - val_accuracy: 0.7807\n",
      "Epoch 411/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.0948 - accuracy: 0.8421 - val_loss: 15.0219 - val_accuracy: 0.7695\n",
      "Epoch 412/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.3098 - accuracy: 0.8513 - val_loss: 13.9100 - val_accuracy: 0.7788\n",
      "Epoch 413/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.2168 - accuracy: 0.8438 - val_loss: 14.7953 - val_accuracy: 0.7932\n",
      "Epoch 414/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.0114 - accuracy: 0.8502 - val_loss: 13.2031 - val_accuracy: 0.7900\n",
      "Epoch 415/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.6806 - accuracy: 0.8604 - val_loss: 15.4010 - val_accuracy: 0.7640\n",
      "Epoch 416/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.3615 - accuracy: 0.8475 - val_loss: 14.1347 - val_accuracy: 0.7783\n",
      "Epoch 417/1000\n",
      "1069/1069 [==============================] - 1s 959us/step - loss: 6.1472 - accuracy: 0.8370 - val_loss: 15.3690 - val_accuracy: 0.7766\n",
      "Epoch 418/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.5755 - accuracy: 0.8340 - val_loss: 14.5292 - val_accuracy: 0.7586\n",
      "Epoch 419/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.5160 - accuracy: 0.8646 - val_loss: 14.5804 - val_accuracy: 0.7829\n",
      "Epoch 420/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.9492 - accuracy: 0.8551 - val_loss: 14.8928 - val_accuracy: 0.7912\n",
      "Epoch 421/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.0782 - accuracy: 0.8494 - val_loss: 14.1683 - val_accuracy: 0.7803\n",
      "Epoch 422/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.2009 - accuracy: 0.8474 - val_loss: 15.4438 - val_accuracy: 0.7526\n",
      "Epoch 423/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.0198 - accuracy: 0.8496 - val_loss: 13.7753 - val_accuracy: 0.7921\n",
      "Epoch 424/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.6443 - accuracy: 0.8514 - val_loss: 13.9955 - val_accuracy: 0.7966\n",
      "Epoch 425/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.4739 - accuracy: 0.8429 - val_loss: 15.0351 - val_accuracy: 0.7579\n",
      "Epoch 426/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.4903 - accuracy: 0.8481 - val_loss: 14.1291 - val_accuracy: 0.7775\n",
      "Epoch 427/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.6431 - accuracy: 0.8408 - val_loss: 15.5383 - val_accuracy: 0.7805\n",
      "Epoch 428/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.2560 - accuracy: 0.8391 - val_loss: 14.3926 - val_accuracy: 0.7796\n",
      "Epoch 429/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.1099 - accuracy: 0.8467 - val_loss: 16.2833 - val_accuracy: 0.7294\n",
      "Epoch 430/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.3311 - accuracy: 0.8408 - val_loss: 15.1419 - val_accuracy: 0.7687\n",
      "Epoch 431/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.1793 - accuracy: 0.8432 - val_loss: 15.7883 - val_accuracy: 0.7768\n",
      "Epoch 432/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.0291 - accuracy: 0.8415 - val_loss: 15.8725 - val_accuracy: 0.7751\n",
      "Epoch 433/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.2926 - accuracy: 0.8553 - val_loss: 15.4341 - val_accuracy: 0.7588\n",
      "Epoch 434/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.8652 - accuracy: 0.8394 - val_loss: 16.1831 - val_accuracy: 0.7790\n",
      "Epoch 435/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.4924 - accuracy: 0.8376 - val_loss: 13.9422 - val_accuracy: 0.7863\n",
      "Epoch 436/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.6459 - accuracy: 0.8510 - val_loss: 16.6917 - val_accuracy: 0.7560\n",
      "Epoch 437/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.3088 - accuracy: 0.8535 - val_loss: 13.8100 - val_accuracy: 0.7985\n",
      "Epoch 438/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.9959 - accuracy: 0.8499 - val_loss: 14.6883 - val_accuracy: 0.8005\n",
      "Epoch 439/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.9054 - accuracy: 0.8488 - val_loss: 16.7960 - val_accuracy: 0.7539\n",
      "Epoch 440/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.3431 - accuracy: 0.8578 - val_loss: 14.5906 - val_accuracy: 0.7910\n",
      "Epoch 441/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.6468 - accuracy: 0.8545 - val_loss: 14.3796 - val_accuracy: 0.7831\n",
      "Epoch 442/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.1187 - accuracy: 0.8442 - val_loss: 15.1319 - val_accuracy: 0.7562\n",
      "Epoch 443/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.0183 - accuracy: 0.8469 - val_loss: 15.5015 - val_accuracy: 0.7635\n",
      "Epoch 444/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.7362 - accuracy: 0.8389 - val_loss: 15.5522 - val_accuracy: 0.7762\n",
      "Epoch 445/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.1741 - accuracy: 0.8430 - val_loss: 14.9118 - val_accuracy: 0.7835\n",
      "Epoch 446/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.2247 - accuracy: 0.8458 - val_loss: 16.7902 - val_accuracy: 0.7307\n",
      "Epoch 447/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.1976 - accuracy: 0.8448 - val_loss: 15.2655 - val_accuracy: 0.7738\n",
      "Epoch 448/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.4050 - accuracy: 0.8469 - val_loss: 16.2865 - val_accuracy: 0.7803\n",
      "Epoch 449/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.8802 - accuracy: 0.8502 - val_loss: 17.1250 - val_accuracy: 0.7667\n",
      "Epoch 450/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.4954 - accuracy: 0.8557 - val_loss: 15.2196 - val_accuracy: 0.7771\n",
      "Epoch 451/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.3106 - accuracy: 0.8446 - val_loss: 15.7854 - val_accuracy: 0.7841\n",
      "Epoch 452/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.2221 - accuracy: 0.8468 - val_loss: 16.0396 - val_accuracy: 0.7541\n",
      "Epoch 453/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.4272 - accuracy: 0.8481 - val_loss: 16.4075 - val_accuracy: 0.7522\n",
      "Epoch 454/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.1878 - accuracy: 0.8408 - val_loss: 15.0589 - val_accuracy: 0.7717\n",
      "Epoch 455/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.9287 - accuracy: 0.8507 - val_loss: 15.5249 - val_accuracy: 0.7805\n",
      "Epoch 456/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.3912 - accuracy: 0.8496 - val_loss: 15.9034 - val_accuracy: 0.7725\n",
      "Epoch 457/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.4172 - accuracy: 0.8530 - val_loss: 15.5645 - val_accuracy: 0.7771\n",
      "Epoch 458/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.1980 - accuracy: 0.8454 - val_loss: 15.0789 - val_accuracy: 0.7764\n",
      "Epoch 459/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.4406 - accuracy: 0.8422 - val_loss: 14.5432 - val_accuracy: 0.7803\n",
      "Epoch 460/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.1318 - accuracy: 0.8521 - val_loss: 15.2907 - val_accuracy: 0.7783\n",
      "Epoch 461/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.5454 - accuracy: 0.8525 - val_loss: 15.0242 - val_accuracy: 0.7818\n",
      "Epoch 462/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.7586 - accuracy: 0.8406 - val_loss: 15.1963 - val_accuracy: 0.7880\n",
      "Epoch 463/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.3164 - accuracy: 0.8486 - val_loss: 14.6404 - val_accuracy: 0.7730\n",
      "Epoch 464/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.3043 - accuracy: 0.8445 - val_loss: 15.8982 - val_accuracy: 0.7635\n",
      "Epoch 465/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.5633 - accuracy: 0.8447 - val_loss: 15.5402 - val_accuracy: 0.7655\n",
      "Epoch 466/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.6234 - accuracy: 0.8402 - val_loss: 16.7025 - val_accuracy: 0.7738\n",
      "Epoch 467/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.6808 - accuracy: 0.8464 - val_loss: 16.0797 - val_accuracy: 0.7706\n",
      "Epoch 468/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.1115 - accuracy: 0.8554 - val_loss: 15.7529 - val_accuracy: 0.7779\n",
      "Epoch 469/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.9735 - accuracy: 0.8575 - val_loss: 15.3158 - val_accuracy: 0.7706\n",
      "Epoch 470/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.1035 - accuracy: 0.8403 - val_loss: 16.6869 - val_accuracy: 0.7565\n",
      "Epoch 471/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.4379 - accuracy: 0.8387 - val_loss: 16.2216 - val_accuracy: 0.7558\n",
      "Epoch 472/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.9578 - accuracy: 0.8557 - val_loss: 16.6807 - val_accuracy: 0.7715\n",
      "Epoch 473/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.3266 - accuracy: 0.8566 - val_loss: 16.2447 - val_accuracy: 0.7790\n",
      "Epoch 474/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.4105 - accuracy: 0.8523 - val_loss: 17.1701 - val_accuracy: 0.7536\n",
      "Epoch 475/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.3552 - accuracy: 0.8416 - val_loss: 16.5612 - val_accuracy: 0.7470\n",
      "Epoch 476/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.1458 - accuracy: 0.8432 - val_loss: 16.2886 - val_accuracy: 0.7691\n",
      "Epoch 477/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.8730 - accuracy: 0.8530 - val_loss: 15.2726 - val_accuracy: 0.7798\n",
      "Epoch 478/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.7315 - accuracy: 0.8635 - val_loss: 15.7371 - val_accuracy: 0.7753\n",
      "Epoch 479/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.5855 - accuracy: 0.8503 - val_loss: 15.3313 - val_accuracy: 0.7852\n",
      "Epoch 480/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.0830 - accuracy: 0.8582 - val_loss: 14.9878 - val_accuracy: 0.7964\n",
      "Epoch 481/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.9332 - accuracy: 0.8571 - val_loss: 15.5393 - val_accuracy: 0.7693\n",
      "Epoch 482/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 5.8508 - accuracy: 0.8556 - val_loss: 15.2639 - val_accuracy: 0.7711\n",
      "Epoch 483/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.3468 - accuracy: 0.8367 - val_loss: 15.2002 - val_accuracy: 0.7831\n",
      "Epoch 484/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.0655 - accuracy: 0.8528 - val_loss: 15.2348 - val_accuracy: 0.7902\n",
      "Epoch 485/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.3715 - accuracy: 0.8560 - val_loss: 16.0215 - val_accuracy: 0.7768\n",
      "Epoch 486/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.2120 - accuracy: 0.8547 - val_loss: 15.5865 - val_accuracy: 0.7854\n",
      "Epoch 487/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.3038 - accuracy: 0.8318 - val_loss: 15.8444 - val_accuracy: 0.7622\n",
      "Epoch 488/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.7188 - accuracy: 0.8350 - val_loss: 16.8622 - val_accuracy: 0.7453\n",
      "Epoch 489/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.8774 - accuracy: 0.8345 - val_loss: 16.6398 - val_accuracy: 0.7754\n",
      "Epoch 490/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.0807 - accuracy: 0.8532 - val_loss: 16.1498 - val_accuracy: 0.7738\n",
      "Epoch 491/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.1288 - accuracy: 0.8380 - val_loss: 17.8106 - val_accuracy: 0.7663\n",
      "Epoch 492/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.8557 - accuracy: 0.8550 - val_loss: 16.0885 - val_accuracy: 0.7781\n",
      "Epoch 493/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.1095 - accuracy: 0.8423 - val_loss: 17.8548 - val_accuracy: 0.7786\n",
      "Epoch 494/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.0753 - accuracy: 0.8454 - val_loss: 16.7406 - val_accuracy: 0.7653\n",
      "Epoch 495/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.9166 - accuracy: 0.8496 - val_loss: 16.9334 - val_accuracy: 0.7726\n",
      "Epoch 496/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.9588 - accuracy: 0.8530 - val_loss: 16.5851 - val_accuracy: 0.7889\n",
      "Epoch 497/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4174 - accuracy: 0.8527 - val_loss: 17.2858 - val_accuracy: 0.8016\n",
      "Epoch 498/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.1495 - accuracy: 0.8556 - val_loss: 16.2725 - val_accuracy: 0.7921\n",
      "Epoch 499/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.0035 - accuracy: 0.8459 - val_loss: 15.7703 - val_accuracy: 0.7912\n",
      "Epoch 500/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.8473 - accuracy: 0.8452 - val_loss: 15.6287 - val_accuracy: 0.7762\n",
      "Epoch 501/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.2663 - accuracy: 0.8366 - val_loss: 16.5061 - val_accuracy: 0.7648\n",
      "Epoch 502/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.6271 - accuracy: 0.8379 - val_loss: 15.8686 - val_accuracy: 0.7889\n",
      "Epoch 503/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7201 - accuracy: 0.8294 - val_loss: 16.3314 - val_accuracy: 0.7915\n",
      "Epoch 504/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8452 - accuracy: 0.8385 - val_loss: 15.4186 - val_accuracy: 0.7827\n",
      "Epoch 505/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5473 - accuracy: 0.8385 - val_loss: 15.3672 - val_accuracy: 0.7829\n",
      "Epoch 506/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9663 - accuracy: 0.8355 - val_loss: 16.2176 - val_accuracy: 0.7824\n",
      "Epoch 507/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4649 - accuracy: 0.8333 - val_loss: 15.5906 - val_accuracy: 0.7859\n",
      "Epoch 508/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3713 - accuracy: 0.8446 - val_loss: 15.7379 - val_accuracy: 0.7811\n",
      "Epoch 509/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.2004 - accuracy: 0.8467 - val_loss: 15.7788 - val_accuracy: 0.7992\n",
      "Epoch 510/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.6235 - accuracy: 0.8472 - val_loss: 17.1165 - val_accuracy: 0.7885\n",
      "Epoch 511/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0878 - accuracy: 0.8406 - val_loss: 17.7364 - val_accuracy: 0.7663\n",
      "Epoch 512/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8034 - accuracy: 0.8392 - val_loss: 18.4918 - val_accuracy: 0.7691\n",
      "Epoch 513/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5974 - accuracy: 0.8360 - val_loss: 17.3991 - val_accuracy: 0.7766\n",
      "Epoch 514/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.8827 - accuracy: 0.8525 - val_loss: 18.6892 - val_accuracy: 0.7766\n",
      "Epoch 515/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4072 - accuracy: 0.8547 - val_loss: 18.4985 - val_accuracy: 0.7734\n",
      "Epoch 516/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.0853 - accuracy: 0.8559 - val_loss: 18.3253 - val_accuracy: 0.7824\n",
      "Epoch 517/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8752 - accuracy: 0.8423 - val_loss: 17.9094 - val_accuracy: 0.7667\n",
      "Epoch 518/1000\n",
      "1069/1069 [==============================] - 1s 987us/step - loss: 6.9266 - accuracy: 0.8540 - val_loss: 16.9731 - val_accuracy: 0.7833\n",
      "Epoch 519/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3841 - accuracy: 0.8478 - val_loss: 18.3637 - val_accuracy: 0.7676\n",
      "Epoch 520/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3625 - accuracy: 0.8412 - val_loss: 17.5786 - val_accuracy: 0.7640\n",
      "Epoch 521/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4601 - accuracy: 0.8375 - val_loss: 18.0892 - val_accuracy: 0.7577\n",
      "Epoch 522/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.1367 - accuracy: 0.8408 - val_loss: 17.7711 - val_accuracy: 0.7820\n",
      "Epoch 523/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5428 - accuracy: 0.8459 - val_loss: 18.8037 - val_accuracy: 0.7605\n",
      "Epoch 524/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5504 - accuracy: 0.8411 - val_loss: 17.6528 - val_accuracy: 0.7682\n",
      "Epoch 525/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4677 - accuracy: 0.8338 - val_loss: 18.3339 - val_accuracy: 0.7597\n",
      "Epoch 526/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.2161 - accuracy: 0.8370 - val_loss: 17.0154 - val_accuracy: 0.7906\n",
      "Epoch 527/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.0869 - accuracy: 0.8641 - val_loss: 18.9329 - val_accuracy: 0.7725\n",
      "Epoch 528/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9948 - accuracy: 0.8517 - val_loss: 18.5035 - val_accuracy: 0.7985\n",
      "Epoch 529/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7146 - accuracy: 0.8539 - val_loss: 18.0910 - val_accuracy: 0.7768\n",
      "Epoch 530/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7142 - accuracy: 0.8503 - val_loss: 17.1809 - val_accuracy: 0.7773\n",
      "Epoch 531/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.8606 - accuracy: 0.8495 - val_loss: 17.1710 - val_accuracy: 0.7839\n",
      "Epoch 532/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.2647 - accuracy: 0.8448 - val_loss: 17.5402 - val_accuracy: 0.7674\n",
      "Epoch 533/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.7703 - accuracy: 0.8582 - val_loss: 16.5841 - val_accuracy: 0.7708\n",
      "Epoch 534/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4622 - accuracy: 0.8339 - val_loss: 17.8203 - val_accuracy: 0.7753\n",
      "Epoch 535/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3919 - accuracy: 0.8445 - val_loss: 17.0417 - val_accuracy: 0.7790\n",
      "Epoch 536/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.0545 - accuracy: 0.8549 - val_loss: 17.0508 - val_accuracy: 0.7904\n",
      "Epoch 537/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.8676 - accuracy: 0.8490 - val_loss: 16.9190 - val_accuracy: 0.7805\n",
      "Epoch 538/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3121 - accuracy: 0.8344 - val_loss: 17.9342 - val_accuracy: 0.7622\n",
      "Epoch 539/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8213 - accuracy: 0.8370 - val_loss: 17.3782 - val_accuracy: 0.7719\n",
      "Epoch 540/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4797 - accuracy: 0.8375 - val_loss: 17.3981 - val_accuracy: 0.7925\n",
      "Epoch 541/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.2034 - accuracy: 0.8539 - val_loss: 16.7290 - val_accuracy: 0.7891\n",
      "Epoch 542/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.9011 - accuracy: 0.8609 - val_loss: 16.7468 - val_accuracy: 0.7852\n",
      "Epoch 543/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5697 - accuracy: 0.8485 - val_loss: 17.7042 - val_accuracy: 0.7848\n",
      "Epoch 544/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3513 - accuracy: 0.8444 - val_loss: 17.3522 - val_accuracy: 0.7747\n",
      "Epoch 545/1000\n",
      "1069/1069 [==============================] - ETA: 0s - loss: 7.1114 - accuracy: 0.85 - 1s 1ms/step - loss: 7.0724 - accuracy: 0.8574 - val_loss: 17.7507 - val_accuracy: 0.7743\n",
      "Epoch 546/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.7827 - accuracy: 0.8491 - val_loss: 17.6173 - val_accuracy: 0.7764\n",
      "Epoch 547/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.8207 - accuracy: 0.8474 - val_loss: 18.0070 - val_accuracy: 0.7655\n",
      "Epoch 548/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.8578 - accuracy: 0.8532 - val_loss: 17.9089 - val_accuracy: 0.7667\n",
      "Epoch 549/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.9847 - accuracy: 0.8512 - val_loss: 18.7770 - val_accuracy: 0.7829\n",
      "Epoch 550/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3198 - accuracy: 0.8511 - val_loss: 18.3316 - val_accuracy: 0.7680\n",
      "Epoch 551/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.7907 - accuracy: 0.8594 - val_loss: 17.7871 - val_accuracy: 0.7762\n",
      "Epoch 552/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.9637 - accuracy: 0.8416 - val_loss: 17.6323 - val_accuracy: 0.7790\n",
      "Epoch 553/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.2093 - accuracy: 0.8420 - val_loss: 18.8167 - val_accuracy: 0.7695\n",
      "Epoch 554/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.6217 - accuracy: 0.8450 - val_loss: 18.8507 - val_accuracy: 0.7640\n",
      "Epoch 555/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.9596 - accuracy: 0.8504 - val_loss: 18.2268 - val_accuracy: 0.7818\n",
      "Epoch 556/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.2390 - accuracy: 0.8485 - val_loss: 19.1042 - val_accuracy: 0.7569\n",
      "Epoch 557/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.1223 - accuracy: 0.8554 - val_loss: 18.0959 - val_accuracy: 0.7788\n",
      "Epoch 558/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.1746 - accuracy: 0.8551 - val_loss: 19.0835 - val_accuracy: 0.7820\n",
      "Epoch 559/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.2939 - accuracy: 0.8520 - val_loss: 19.0146 - val_accuracy: 0.7687\n",
      "Epoch 560/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.9156 - accuracy: 0.8533 - val_loss: 18.2721 - val_accuracy: 0.7708\n",
      "Epoch 561/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.9699 - accuracy: 0.8441 - val_loss: 18.0385 - val_accuracy: 0.7846\n",
      "Epoch 562/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.5524 - accuracy: 0.8571 - val_loss: 18.4918 - val_accuracy: 0.7734\n",
      "Epoch 563/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.1262 - accuracy: 0.8520 - val_loss: 18.4391 - val_accuracy: 0.7771\n",
      "Epoch 564/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.8361 - accuracy: 0.8495 - val_loss: 18.1017 - val_accuracy: 0.7723\n",
      "Epoch 565/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.8096 - accuracy: 0.8459 - val_loss: 18.0999 - val_accuracy: 0.7680\n",
      "Epoch 566/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.2759 - accuracy: 0.8592 - val_loss: 17.8004 - val_accuracy: 0.7745\n",
      "Epoch 567/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.6847 - accuracy: 0.8534 - val_loss: 18.3176 - val_accuracy: 0.7756\n",
      "Epoch 568/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.7666 - accuracy: 0.8526 - val_loss: 17.6292 - val_accuracy: 0.7768\n",
      "Epoch 569/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.5574 - accuracy: 0.8514 - val_loss: 18.9336 - val_accuracy: 0.7521\n",
      "Epoch 570/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.6908 - accuracy: 0.8464 - val_loss: 17.6553 - val_accuracy: 0.7698\n",
      "Epoch 571/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.3847 - accuracy: 0.8551 - val_loss: 18.3017 - val_accuracy: 0.7805\n",
      "Epoch 572/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.0177 - accuracy: 0.8496 - val_loss: 19.0861 - val_accuracy: 0.7532\n",
      "Epoch 573/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.0229 - accuracy: 0.8482 - val_loss: 18.2132 - val_accuracy: 0.7696\n",
      "Epoch 574/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.1164 - accuracy: 0.8392 - val_loss: 17.6156 - val_accuracy: 0.7710\n",
      "Epoch 575/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.5383 - accuracy: 0.8537 - val_loss: 18.3218 - val_accuracy: 0.7653\n",
      "Epoch 576/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.9472 - accuracy: 0.8531 - val_loss: 17.7579 - val_accuracy: 0.7790\n",
      "Epoch 577/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.7569 - accuracy: 0.8563 - val_loss: 18.0416 - val_accuracy: 0.7837\n",
      "Epoch 578/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.1421 - accuracy: 0.8523 - val_loss: 18.4094 - val_accuracy: 0.7760\n",
      "Epoch 579/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.6843 - accuracy: 0.8569 - val_loss: 17.9236 - val_accuracy: 0.7904\n",
      "Epoch 580/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.6306 - accuracy: 0.8568 - val_loss: 18.1461 - val_accuracy: 0.7758\n",
      "Epoch 581/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.6452 - accuracy: 0.8520 - val_loss: 18.4233 - val_accuracy: 0.7586\n",
      "Epoch 582/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.0006 - accuracy: 0.8343 - val_loss: 18.1556 - val_accuracy: 0.7573\n",
      "Epoch 583/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.7360 - accuracy: 0.8381 - val_loss: 17.6051 - val_accuracy: 0.7764\n",
      "Epoch 584/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.5360 - accuracy: 0.8557 - val_loss: 18.4453 - val_accuracy: 0.7717\n",
      "Epoch 585/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.6259 - accuracy: 0.8562 - val_loss: 17.6538 - val_accuracy: 0.7857\n",
      "Epoch 586/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.4810 - accuracy: 0.8487 - val_loss: 17.7578 - val_accuracy: 0.7693\n",
      "Epoch 587/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.0082 - accuracy: 0.8423 - val_loss: 18.5191 - val_accuracy: 0.7601\n",
      "Epoch 588/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.7473 - accuracy: 0.8482 - val_loss: 17.4724 - val_accuracy: 0.7790\n",
      "Epoch 589/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.5720 - accuracy: 0.8542 - val_loss: 17.7747 - val_accuracy: 0.7899\n",
      "Epoch 590/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.8748 - accuracy: 0.8560 - val_loss: 19.2271 - val_accuracy: 0.7625\n",
      "Epoch 591/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.6503 - accuracy: 0.8482 - val_loss: 18.7337 - val_accuracy: 0.7865\n",
      "Epoch 592/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3951 - accuracy: 0.8498 - val_loss: 18.5796 - val_accuracy: 0.7788\n",
      "Epoch 593/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.6053 - accuracy: 0.8524 - val_loss: 19.6665 - val_accuracy: 0.7667\n",
      "Epoch 594/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3302 - accuracy: 0.8498 - val_loss: 18.5253 - val_accuracy: 0.7790\n",
      "Epoch 595/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4291 - accuracy: 0.8399 - val_loss: 18.9605 - val_accuracy: 0.7758\n",
      "Epoch 596/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5564 - accuracy: 0.8495 - val_loss: 19.5955 - val_accuracy: 0.7618\n",
      "Epoch 597/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4397 - accuracy: 0.8470 - val_loss: 18.6371 - val_accuracy: 0.7897\n",
      "Epoch 598/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.0233 - accuracy: 0.8536 - val_loss: 17.9190 - val_accuracy: 0.7796\n",
      "Epoch 599/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.0949 - accuracy: 0.8545 - val_loss: 19.5355 - val_accuracy: 0.7541\n",
      "Epoch 600/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8308 - accuracy: 0.8355 - val_loss: 19.5657 - val_accuracy: 0.7710\n",
      "Epoch 601/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0078 - accuracy: 0.8363 - val_loss: 19.2035 - val_accuracy: 0.7696\n",
      "Epoch 602/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5854 - accuracy: 0.8492 - val_loss: 18.9986 - val_accuracy: 0.7659\n",
      "Epoch 603/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3511 - accuracy: 0.8428 - val_loss: 19.1421 - val_accuracy: 0.7857\n",
      "Epoch 604/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3707 - accuracy: 0.8431 - val_loss: 19.1349 - val_accuracy: 0.7590\n",
      "Epoch 605/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7458 - accuracy: 0.8467 - val_loss: 19.4467 - val_accuracy: 0.7691\n",
      "Epoch 606/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.2659 - accuracy: 0.8420 - val_loss: 19.7659 - val_accuracy: 0.7831\n",
      "Epoch 607/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0725 - accuracy: 0.8485 - val_loss: 19.3429 - val_accuracy: 0.7775\n",
      "Epoch 608/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.2995 - accuracy: 0.8624 - val_loss: 17.9511 - val_accuracy: 0.7910\n",
      "Epoch 609/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5141 - accuracy: 0.8423 - val_loss: 18.3322 - val_accuracy: 0.7874\n",
      "Epoch 610/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5254 - accuracy: 0.8517 - val_loss: 19.7337 - val_accuracy: 0.7670\n",
      "Epoch 611/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8533 - accuracy: 0.8450 - val_loss: 18.6960 - val_accuracy: 0.7766\n",
      "Epoch 612/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.2191 - accuracy: 0.8484 - val_loss: 17.8545 - val_accuracy: 0.7805\n",
      "Epoch 613/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.0470 - accuracy: 0.8530 - val_loss: 19.4494 - val_accuracy: 0.7599\n",
      "Epoch 614/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.1747 - accuracy: 0.8529 - val_loss: 18.3441 - val_accuracy: 0.7871\n",
      "Epoch 615/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.0747 - accuracy: 0.8481 - val_loss: 18.7969 - val_accuracy: 0.7809\n",
      "Epoch 616/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3928 - accuracy: 0.8493 - val_loss: 19.6226 - val_accuracy: 0.7558\n",
      "Epoch 617/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.0209 - accuracy: 0.8416 - val_loss: 18.6739 - val_accuracy: 0.7633\n",
      "Epoch 618/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.9830 - accuracy: 0.8345 - val_loss: 18.8063 - val_accuracy: 0.7698\n",
      "Epoch 619/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.5881 - accuracy: 0.8519 - val_loss: 19.2479 - val_accuracy: 0.7715\n",
      "Epoch 620/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.1003 - accuracy: 0.8585 - val_loss: 19.3605 - val_accuracy: 0.7820\n",
      "Epoch 621/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.8402 - accuracy: 0.8587 - val_loss: 18.5949 - val_accuracy: 0.7857\n",
      "Epoch 622/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.8170 - accuracy: 0.8577 - val_loss: 19.0976 - val_accuracy: 0.7676\n",
      "Epoch 623/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.8841 - accuracy: 0.8510 - val_loss: 18.2949 - val_accuracy: 0.7769\n",
      "Epoch 624/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.7988 - accuracy: 0.8554 - val_loss: 19.1689 - val_accuracy: 0.7745\n",
      "Epoch 625/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4485 - accuracy: 0.8520 - val_loss: 19.1974 - val_accuracy: 0.7676\n",
      "Epoch 626/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.8267 - accuracy: 0.8565 - val_loss: 18.6944 - val_accuracy: 0.7775\n",
      "Epoch 627/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3413 - accuracy: 0.8430 - val_loss: 18.5260 - val_accuracy: 0.7726\n",
      "Epoch 628/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.3429 - accuracy: 0.8594 - val_loss: 18.5986 - val_accuracy: 0.7730\n",
      "Epoch 629/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.9742 - accuracy: 0.8510 - val_loss: 19.3590 - val_accuracy: 0.7682\n",
      "Epoch 630/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.0061 - accuracy: 0.8455 - val_loss: 18.6914 - val_accuracy: 0.7610\n",
      "Epoch 631/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.1433 - accuracy: 0.8426 - val_loss: 18.9675 - val_accuracy: 0.7603\n",
      "Epoch 632/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.8996 - accuracy: 0.8500 - val_loss: 18.3595 - val_accuracy: 0.7865\n",
      "Epoch 633/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.2125 - accuracy: 0.8524 - val_loss: 19.3235 - val_accuracy: 0.7811\n",
      "Epoch 634/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3500 - accuracy: 0.8601 - val_loss: 18.6328 - val_accuracy: 0.7835\n",
      "Epoch 635/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.8262 - accuracy: 0.8561 - val_loss: 18.5850 - val_accuracy: 0.7811\n",
      "Epoch 636/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.1684 - accuracy: 0.8437 - val_loss: 18.6595 - val_accuracy: 0.7663\n",
      "Epoch 637/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.6457 - accuracy: 0.8530 - val_loss: 19.0470 - val_accuracy: 0.7640\n",
      "Epoch 638/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.9187 - accuracy: 0.8512 - val_loss: 18.4683 - val_accuracy: 0.7792\n",
      "Epoch 639/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 6.4327 - accuracy: 0.8540 - val_loss: 18.2735 - val_accuracy: 0.7764\n",
      "Epoch 640/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.1374 - accuracy: 0.8479 - val_loss: 19.0821 - val_accuracy: 0.7680\n",
      "Epoch 641/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 6.9679 - accuracy: 0.8511 - val_loss: 18.6304 - val_accuracy: 0.7786\n",
      "Epoch 642/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 6.8983 - accuracy: 0.8512 - val_loss: 19.1972 - val_accuracy: 0.7753\n",
      "Epoch 643/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 6.8736 - accuracy: 0.8532 - val_loss: 19.6682 - val_accuracy: 0.7588\n",
      "Epoch 644/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 7.0246 - accuracy: 0.8451 - val_loss: 19.0809 - val_accuracy: 0.7676\n",
      "Epoch 645/1000\n",
      "1069/1069 [==============================] - 2s 1ms/step - loss: 6.8793 - accuracy: 0.8441 - val_loss: 18.5860 - val_accuracy: 0.7764\n",
      "Epoch 646/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 6.6105 - accuracy: 0.8573 - val_loss: 19.4602 - val_accuracy: 0.7687\n",
      "Epoch 647/1000\n",
      "1069/1069 [==============================] - 2s 1ms/step - loss: 7.0267 - accuracy: 0.8549 - val_loss: 18.4903 - val_accuracy: 0.7811\n",
      "Epoch 648/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 6.9241 - accuracy: 0.8475 - val_loss: 18.3828 - val_accuracy: 0.7640\n",
      "Epoch 649/1000\n",
      "1069/1069 [==============================] - 2s 1ms/step - loss: 7.2901 - accuracy: 0.8422 - val_loss: 18.9864 - val_accuracy: 0.7597\n",
      "Epoch 650/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 6.8460 - accuracy: 0.8522 - val_loss: 18.1478 - val_accuracy: 0.7814\n",
      "Epoch 651/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 7.1628 - accuracy: 0.8525 - val_loss: 18.7197 - val_accuracy: 0.7844\n",
      "Epoch 652/1000\n",
      "1069/1069 [==============================] - 2s 1ms/step - loss: 7.1747 - accuracy: 0.8548 - val_loss: 18.9849 - val_accuracy: 0.7683\n",
      "Epoch 653/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 7.1582 - accuracy: 0.8491 - val_loss: 18.6948 - val_accuracy: 0.7758\n",
      "Epoch 654/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 6.9986 - accuracy: 0.8425 - val_loss: 18.3084 - val_accuracy: 0.7721\n",
      "Epoch 655/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 7.0678 - accuracy: 0.8484 - val_loss: 19.6222 - val_accuracy: 0.7618\n",
      "Epoch 656/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 7.1838 - accuracy: 0.8499 - val_loss: 17.7038 - val_accuracy: 0.7837\n",
      "Epoch 657/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 6.7116 - accuracy: 0.8541 - val_loss: 17.5784 - val_accuracy: 0.7829\n",
      "Epoch 658/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 7.5248 - accuracy: 0.8541 - val_loss: 19.0059 - val_accuracy: 0.7642\n",
      "Epoch 659/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 7.7765 - accuracy: 0.8490 - val_loss: 18.6824 - val_accuracy: 0.7880\n",
      "Epoch 660/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 7.8494 - accuracy: 0.8497 - val_loss: 18.9911 - val_accuracy: 0.7730\n",
      "Epoch 661/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 7.4178 - accuracy: 0.8576 - val_loss: 18.6290 - val_accuracy: 0.7747\n",
      "Epoch 662/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 7.6855 - accuracy: 0.8391 - val_loss: 19.3268 - val_accuracy: 0.7775\n",
      "Epoch 663/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 7.8456 - accuracy: 0.8370 - val_loss: 19.8092 - val_accuracy: 0.7579\n",
      "Epoch 664/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 7.1800 - accuracy: 0.8527 - val_loss: 19.1695 - val_accuracy: 0.7670\n",
      "Epoch 665/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 7.5304 - accuracy: 0.8415 - val_loss: 19.9386 - val_accuracy: 0.7676\n",
      "Epoch 666/1000\n",
      "1069/1069 [==============================] - 2s 2ms/step - loss: 7.4295 - accuracy: 0.8373 - val_loss: 19.4347 - val_accuracy: 0.7506\n",
      "Epoch 667/1000\n",
      "1069/1069 [==============================] - 2s 1ms/step - loss: 7.6141 - accuracy: 0.8359 - val_loss: 19.6007 - val_accuracy: 0.7513\n",
      "Epoch 668/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4231 - accuracy: 0.8377 - val_loss: 18.7953 - val_accuracy: 0.7689\n",
      "Epoch 669/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4976 - accuracy: 0.8471 - val_loss: 19.5279 - val_accuracy: 0.7768\n",
      "Epoch 670/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.2458 - accuracy: 0.8584 - val_loss: 19.2722 - val_accuracy: 0.7682\n",
      "Epoch 671/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3544 - accuracy: 0.8506 - val_loss: 20.1199 - val_accuracy: 0.7775\n",
      "Epoch 672/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7888 - accuracy: 0.8429 - val_loss: 19.5564 - val_accuracy: 0.7659\n",
      "Epoch 673/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8098 - accuracy: 0.8518 - val_loss: 20.4969 - val_accuracy: 0.7685\n",
      "Epoch 674/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.3744 - accuracy: 0.8417 - val_loss: 19.7742 - val_accuracy: 0.7854\n",
      "Epoch 675/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.6530 - accuracy: 0.8467 - val_loss: 19.6760 - val_accuracy: 0.7682\n",
      "Epoch 676/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9911 - accuracy: 0.8492 - val_loss: 18.9387 - val_accuracy: 0.7773\n",
      "Epoch 677/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.6498 - accuracy: 0.8355 - val_loss: 19.2664 - val_accuracy: 0.7803\n",
      "Epoch 678/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.2984 - accuracy: 0.8438 - val_loss: 21.6197 - val_accuracy: 0.7481\n",
      "Epoch 679/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.6647 - accuracy: 0.8412 - val_loss: 18.7466 - val_accuracy: 0.7721\n",
      "Epoch 680/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.2360 - accuracy: 0.8347 - val_loss: 19.3559 - val_accuracy: 0.7668\n",
      "Epoch 681/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.6961 - accuracy: 0.8401 - val_loss: 20.2555 - val_accuracy: 0.7580\n",
      "Epoch 682/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5625 - accuracy: 0.8533 - val_loss: 19.6564 - val_accuracy: 0.7865\n",
      "Epoch 683/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.1080 - accuracy: 0.8468 - val_loss: 19.3423 - val_accuracy: 0.7872\n",
      "Epoch 684/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7653 - accuracy: 0.8604 - val_loss: 20.2302 - val_accuracy: 0.7682\n",
      "Epoch 685/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0576 - accuracy: 0.8459 - val_loss: 19.7246 - val_accuracy: 0.7829\n",
      "Epoch 686/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.6801 - accuracy: 0.8448 - val_loss: 19.3984 - val_accuracy: 0.7713\n",
      "Epoch 687/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5907 - accuracy: 0.8568 - val_loss: 19.3922 - val_accuracy: 0.7775\n",
      "Epoch 688/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0662 - accuracy: 0.8391 - val_loss: 20.0181 - val_accuracy: 0.7809\n",
      "Epoch 689/1000\n",
      "1069/1069 [==============================] - 1s 970us/step - loss: 8.1065 - accuracy: 0.8410 - val_loss: 20.8760 - val_accuracy: 0.7502\n",
      "Epoch 690/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.6842 - accuracy: 0.8534 - val_loss: 19.4243 - val_accuracy: 0.7760\n",
      "Epoch 691/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5401 - accuracy: 0.8441 - val_loss: 19.5881 - val_accuracy: 0.7745\n",
      "Epoch 692/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9980 - accuracy: 0.8499 - val_loss: 21.9054 - val_accuracy: 0.7504\n",
      "Epoch 693/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9259 - accuracy: 0.8470 - val_loss: 19.6570 - val_accuracy: 0.7777\n",
      "Epoch 694/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7344 - accuracy: 0.8413 - val_loss: 19.8389 - val_accuracy: 0.7683\n",
      "Epoch 695/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0754 - accuracy: 0.8514 - val_loss: 19.9760 - val_accuracy: 0.7700\n",
      "Epoch 696/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.2098 - accuracy: 0.8447 - val_loss: 20.3673 - val_accuracy: 0.7904\n",
      "Epoch 697/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.6370 - accuracy: 0.8465 - val_loss: 21.4298 - val_accuracy: 0.7629\n",
      "Epoch 698/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.2665 - accuracy: 0.8532 - val_loss: 19.2050 - val_accuracy: 0.7839\n",
      "Epoch 699/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.2972 - accuracy: 0.8391 - val_loss: 19.4073 - val_accuracy: 0.7749\n",
      "Epoch 700/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9291 - accuracy: 0.8494 - val_loss: 21.0038 - val_accuracy: 0.7642\n",
      "Epoch 701/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8502 - accuracy: 0.8523 - val_loss: 20.1016 - val_accuracy: 0.7839\n",
      "Epoch 702/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0112 - accuracy: 0.8415 - val_loss: 20.5601 - val_accuracy: 0.7650\n",
      "Epoch 703/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9675 - accuracy: 0.8447 - val_loss: 20.0846 - val_accuracy: 0.7552\n",
      "Epoch 704/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8138 - accuracy: 0.8343 - val_loss: 20.0831 - val_accuracy: 0.7683\n",
      "Epoch 705/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4713 - accuracy: 0.8476 - val_loss: 20.1587 - val_accuracy: 0.7693\n",
      "Epoch 706/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8115 - accuracy: 0.8557 - val_loss: 19.5166 - val_accuracy: 0.7859\n",
      "Epoch 707/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7670 - accuracy: 0.8544 - val_loss: 18.8366 - val_accuracy: 0.7949\n",
      "Epoch 708/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8586 - accuracy: 0.8558 - val_loss: 19.4769 - val_accuracy: 0.7730\n",
      "Epoch 709/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8226 - accuracy: 0.8512 - val_loss: 18.5343 - val_accuracy: 0.7792\n",
      "Epoch 710/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7783 - accuracy: 0.8417 - val_loss: 19.0836 - val_accuracy: 0.7713\n",
      "Epoch 711/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9062 - accuracy: 0.8453 - val_loss: 19.5542 - val_accuracy: 0.7612\n",
      "Epoch 712/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5696 - accuracy: 0.8484 - val_loss: 18.6918 - val_accuracy: 0.7820\n",
      "Epoch 713/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.6983 - accuracy: 0.8502 - val_loss: 19.3422 - val_accuracy: 0.7816\n",
      "Epoch 714/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0006 - accuracy: 0.8572 - val_loss: 19.8194 - val_accuracy: 0.7784\n",
      "Epoch 715/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0280 - accuracy: 0.8510 - val_loss: 20.0038 - val_accuracy: 0.7831\n",
      "Epoch 716/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9670 - accuracy: 0.8456 - val_loss: 19.4270 - val_accuracy: 0.7687\n",
      "Epoch 717/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8036 - accuracy: 0.8419 - val_loss: 20.1186 - val_accuracy: 0.7552\n",
      "Epoch 718/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0874 - accuracy: 0.8326 - val_loss: 19.2643 - val_accuracy: 0.7730\n",
      "Epoch 719/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3700 - accuracy: 0.8479 - val_loss: 19.4125 - val_accuracy: 0.7726\n",
      "Epoch 720/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7862 - accuracy: 0.8556 - val_loss: 19.7737 - val_accuracy: 0.7809\n",
      "Epoch 721/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.2331 - accuracy: 0.8505 - val_loss: 19.9415 - val_accuracy: 0.7865\n",
      "Epoch 722/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.1408 - accuracy: 0.8509 - val_loss: 20.4469 - val_accuracy: 0.7543\n",
      "Epoch 723/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9586 - accuracy: 0.8440 - val_loss: 19.9455 - val_accuracy: 0.7710\n",
      "Epoch 724/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9062 - accuracy: 0.8395 - val_loss: 19.8245 - val_accuracy: 0.7667\n",
      "Epoch 725/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.6043 - accuracy: 0.8502 - val_loss: 19.7557 - val_accuracy: 0.7702\n",
      "Epoch 726/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4568 - accuracy: 0.8498 - val_loss: 19.6506 - val_accuracy: 0.7801\n",
      "Epoch 727/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0461 - accuracy: 0.8439 - val_loss: 20.1042 - val_accuracy: 0.7756\n",
      "Epoch 728/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9727 - accuracy: 0.8549 - val_loss: 19.9103 - val_accuracy: 0.7783\n",
      "Epoch 729/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8603 - accuracy: 0.8438 - val_loss: 19.9256 - val_accuracy: 0.7758\n",
      "Epoch 730/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7103 - accuracy: 0.8431 - val_loss: 19.6219 - val_accuracy: 0.7577\n",
      "Epoch 731/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5300 - accuracy: 0.8418 - val_loss: 18.8599 - val_accuracy: 0.7711\n",
      "Epoch 732/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5514 - accuracy: 0.8450 - val_loss: 18.7086 - val_accuracy: 0.7857\n",
      "Epoch 733/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9090 - accuracy: 0.8496 - val_loss: 19.2794 - val_accuracy: 0.7827\n",
      "Epoch 734/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9447 - accuracy: 0.8595 - val_loss: 18.7447 - val_accuracy: 0.7936\n",
      "Epoch 735/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3968 - accuracy: 0.8574 - val_loss: 18.7115 - val_accuracy: 0.7900\n",
      "Epoch 736/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9197 - accuracy: 0.8490 - val_loss: 19.5505 - val_accuracy: 0.7715\n",
      "Epoch 737/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9903 - accuracy: 0.8423 - val_loss: 19.2644 - val_accuracy: 0.7788\n",
      "Epoch 738/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8229 - accuracy: 0.8500 - val_loss: 19.6183 - val_accuracy: 0.7730\n",
      "Epoch 739/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9114 - accuracy: 0.8492 - val_loss: 19.6601 - val_accuracy: 0.7781\n",
      "Epoch 740/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.1716 - accuracy: 0.8474 - val_loss: 20.0533 - val_accuracy: 0.7760\n",
      "Epoch 741/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.6061 - accuracy: 0.8524 - val_loss: 19.2671 - val_accuracy: 0.7846\n",
      "Epoch 742/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.6522 - accuracy: 0.8527 - val_loss: 20.0237 - val_accuracy: 0.7777\n",
      "Epoch 743/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.1268 - accuracy: 0.8477 - val_loss: 19.9968 - val_accuracy: 0.7749\n",
      "Epoch 744/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.6183 - accuracy: 0.8502 - val_loss: 18.9907 - val_accuracy: 0.7865\n",
      "Epoch 745/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.1420 - accuracy: 0.8580 - val_loss: 19.0846 - val_accuracy: 0.7762\n",
      "Epoch 746/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8298 - accuracy: 0.8529 - val_loss: 20.0357 - val_accuracy: 0.7803\n",
      "Epoch 747/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.2950 - accuracy: 0.8500 - val_loss: 19.6598 - val_accuracy: 0.7775\n",
      "Epoch 748/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9222 - accuracy: 0.8493 - val_loss: 19.3186 - val_accuracy: 0.7762\n",
      "Epoch 749/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5313 - accuracy: 0.8493 - val_loss: 19.5852 - val_accuracy: 0.7710\n",
      "Epoch 750/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9230 - accuracy: 0.8389 - val_loss: 19.9697 - val_accuracy: 0.7717\n",
      "Epoch 751/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7805 - accuracy: 0.8500 - val_loss: 20.0377 - val_accuracy: 0.7713\n",
      "Epoch 752/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.6232 - accuracy: 0.8472 - val_loss: 19.5746 - val_accuracy: 0.7786\n",
      "Epoch 753/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4495 - accuracy: 0.8465 - val_loss: 19.6968 - val_accuracy: 0.7663\n",
      "Epoch 754/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4034 - accuracy: 0.8419 - val_loss: 19.7386 - val_accuracy: 0.7575\n",
      "Epoch 755/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4137 - accuracy: 0.8389 - val_loss: 19.6508 - val_accuracy: 0.7655\n",
      "Epoch 756/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7011 - accuracy: 0.8351 - val_loss: 19.7728 - val_accuracy: 0.7702\n",
      "Epoch 757/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.1076 - accuracy: 0.8430 - val_loss: 20.3911 - val_accuracy: 0.7663\n",
      "Epoch 758/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9408 - accuracy: 0.8504 - val_loss: 19.4485 - val_accuracy: 0.7930\n",
      "Epoch 759/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9076 - accuracy: 0.8546 - val_loss: 19.7092 - val_accuracy: 0.7943\n",
      "Epoch 760/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.1134 - accuracy: 0.8546 - val_loss: 20.0470 - val_accuracy: 0.7769\n",
      "Epoch 761/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.1183 - accuracy: 0.8486 - val_loss: 20.4846 - val_accuracy: 0.7801\n",
      "Epoch 762/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.2985 - accuracy: 0.8373 - val_loss: 20.9422 - val_accuracy: 0.7517\n",
      "Epoch 763/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0537 - accuracy: 0.8447 - val_loss: 20.0288 - val_accuracy: 0.7717\n",
      "Epoch 764/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7563 - accuracy: 0.8454 - val_loss: 20.1994 - val_accuracy: 0.7745\n",
      "Epoch 765/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.4010 - accuracy: 0.8487 - val_loss: 21.7840 - val_accuracy: 0.7610\n",
      "Epoch 766/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.2388 - accuracy: 0.8478 - val_loss: 19.8938 - val_accuracy: 0.7747\n",
      "Epoch 767/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9738 - accuracy: 0.8371 - val_loss: 20.0342 - val_accuracy: 0.7687\n",
      "Epoch 768/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0434 - accuracy: 0.8401 - val_loss: 21.2072 - val_accuracy: 0.7479\n",
      "Epoch 769/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.2374 - accuracy: 0.8312 - val_loss: 20.4406 - val_accuracy: 0.7668\n",
      "Epoch 770/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9814 - accuracy: 0.8403 - val_loss: 19.7466 - val_accuracy: 0.7732\n",
      "Epoch 771/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9779 - accuracy: 0.8525 - val_loss: 20.0170 - val_accuracy: 0.7842\n",
      "Epoch 772/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.4318 - accuracy: 0.8514 - val_loss: 19.4994 - val_accuracy: 0.7947\n",
      "Epoch 773/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.2990 - accuracy: 0.8523 - val_loss: 19.3458 - val_accuracy: 0.7859\n",
      "Epoch 774/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7293 - accuracy: 0.8610 - val_loss: 18.6627 - val_accuracy: 0.7861\n",
      "Epoch 775/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9944 - accuracy: 0.8415 - val_loss: 19.3627 - val_accuracy: 0.7691\n",
      "Epoch 776/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.5451 - accuracy: 0.8349 - val_loss: 20.1962 - val_accuracy: 0.7601\n",
      "Epoch 777/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8650 - accuracy: 0.8460 - val_loss: 18.7798 - val_accuracy: 0.7820\n",
      "Epoch 778/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8341 - accuracy: 0.8547 - val_loss: 19.5637 - val_accuracy: 0.7899\n",
      "Epoch 779/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.3097 - accuracy: 0.8560 - val_loss: 20.1970 - val_accuracy: 0.7747\n",
      "Epoch 780/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.2960 - accuracy: 0.8475 - val_loss: 19.8624 - val_accuracy: 0.7878\n",
      "Epoch 781/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.2940 - accuracy: 0.8431 - val_loss: 20.1500 - val_accuracy: 0.7603\n",
      "Epoch 782/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.1760 - accuracy: 0.8383 - val_loss: 19.9537 - val_accuracy: 0.7629\n",
      "Epoch 783/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9134 - accuracy: 0.8373 - val_loss: 18.9526 - val_accuracy: 0.7754\n",
      "Epoch 784/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3632 - accuracy: 0.8496 - val_loss: 19.4134 - val_accuracy: 0.7760\n",
      "Epoch 785/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8019 - accuracy: 0.8555 - val_loss: 19.3700 - val_accuracy: 0.7822\n",
      "Epoch 786/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0832 - accuracy: 0.8465 - val_loss: 19.4441 - val_accuracy: 0.7895\n",
      "Epoch 787/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.2683 - accuracy: 0.8496 - val_loss: 20.2815 - val_accuracy: 0.7734\n",
      "Epoch 788/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.4443 - accuracy: 0.8418 - val_loss: 19.6909 - val_accuracy: 0.7745\n",
      "Epoch 789/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9098 - accuracy: 0.8385 - val_loss: 19.2445 - val_accuracy: 0.7751\n",
      "Epoch 790/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8236 - accuracy: 0.8427 - val_loss: 20.1341 - val_accuracy: 0.7721\n",
      "Epoch 791/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.1448 - accuracy: 0.8514 - val_loss: 19.7905 - val_accuracy: 0.7899\n",
      "Epoch 792/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9477 - accuracy: 0.8505 - val_loss: 19.2361 - val_accuracy: 0.7947\n",
      "Epoch 793/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3382 - accuracy: 0.8585 - val_loss: 19.7358 - val_accuracy: 0.7764\n",
      "Epoch 794/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4238 - accuracy: 0.8508 - val_loss: 19.3153 - val_accuracy: 0.7749\n",
      "Epoch 795/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8764 - accuracy: 0.8408 - val_loss: 19.4660 - val_accuracy: 0.7749\n",
      "Epoch 796/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.6967 - accuracy: 0.8460 - val_loss: 19.4658 - val_accuracy: 0.7670\n",
      "Epoch 797/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7348 - accuracy: 0.8474 - val_loss: 19.3580 - val_accuracy: 0.7837\n",
      "Epoch 798/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7887 - accuracy: 0.8454 - val_loss: 19.2191 - val_accuracy: 0.7773\n",
      "Epoch 799/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.6447 - accuracy: 0.8520 - val_loss: 19.8517 - val_accuracy: 0.7726\n",
      "Epoch 800/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5846 - accuracy: 0.8518 - val_loss: 19.4166 - val_accuracy: 0.7764\n",
      "Epoch 801/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.1905 - accuracy: 0.8422 - val_loss: 20.3900 - val_accuracy: 0.7663\n",
      "Epoch 802/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.3921 - accuracy: 0.8467 - val_loss: 20.2666 - val_accuracy: 0.7642\n",
      "Epoch 803/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7632 - accuracy: 0.8491 - val_loss: 19.4852 - val_accuracy: 0.7807\n",
      "Epoch 804/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3654 - accuracy: 0.8536 - val_loss: 19.3065 - val_accuracy: 0.7734\n",
      "Epoch 805/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5108 - accuracy: 0.8495 - val_loss: 19.2345 - val_accuracy: 0.7700\n",
      "Epoch 806/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7440 - accuracy: 0.8418 - val_loss: 19.3614 - val_accuracy: 0.7648\n",
      "Epoch 807/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7990 - accuracy: 0.8382 - val_loss: 19.5494 - val_accuracy: 0.7573\n",
      "Epoch 808/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7897 - accuracy: 0.8405 - val_loss: 19.6201 - val_accuracy: 0.7652\n",
      "Epoch 809/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5482 - accuracy: 0.8431 - val_loss: 19.2259 - val_accuracy: 0.7786\n",
      "Epoch 810/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.1203 - accuracy: 0.8606 - val_loss: 19.2847 - val_accuracy: 0.7826\n",
      "Epoch 811/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.0827 - accuracy: 0.8614 - val_loss: 19.3090 - val_accuracy: 0.7876\n",
      "Epoch 812/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.1574 - accuracy: 0.8582 - val_loss: 19.7574 - val_accuracy: 0.7760\n",
      "Epoch 813/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4163 - accuracy: 0.8486 - val_loss: 19.7219 - val_accuracy: 0.7711\n",
      "Epoch 814/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.6170 - accuracy: 0.8445 - val_loss: 19.6989 - val_accuracy: 0.7670\n",
      "Epoch 815/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3612 - accuracy: 0.8530 - val_loss: 19.2507 - val_accuracy: 0.7781\n",
      "Epoch 816/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4303 - accuracy: 0.8544 - val_loss: 19.3584 - val_accuracy: 0.7799\n",
      "Epoch 817/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7468 - accuracy: 0.8565 - val_loss: 19.5886 - val_accuracy: 0.7801\n",
      "Epoch 818/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5279 - accuracy: 0.8563 - val_loss: 18.9978 - val_accuracy: 0.7792\n",
      "Epoch 819/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.2057 - accuracy: 0.8518 - val_loss: 19.2445 - val_accuracy: 0.7695\n",
      "Epoch 820/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5854 - accuracy: 0.8415 - val_loss: 19.8307 - val_accuracy: 0.7592\n",
      "Epoch 821/1000\n",
      "1069/1069 [==============================] - 1s 988us/step - loss: 7.4733 - accuracy: 0.8406 - val_loss: 19.0485 - val_accuracy: 0.7713\n",
      "Epoch 822/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.0993 - accuracy: 0.8511 - val_loss: 19.1318 - val_accuracy: 0.7753\n",
      "Epoch 823/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5257 - accuracy: 0.8568 - val_loss: 19.2066 - val_accuracy: 0.7826\n",
      "Epoch 824/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7102 - accuracy: 0.8525 - val_loss: 19.0655 - val_accuracy: 0.7921\n",
      "Epoch 825/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4569 - accuracy: 0.8540 - val_loss: 18.8984 - val_accuracy: 0.7762\n",
      "Epoch 826/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.3393 - accuracy: 0.8491 - val_loss: 18.6674 - val_accuracy: 0.7708\n",
      "Epoch 827/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8420 - accuracy: 0.8346 - val_loss: 18.8674 - val_accuracy: 0.7668\n",
      "Epoch 828/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7728 - accuracy: 0.8354 - val_loss: 18.8118 - val_accuracy: 0.7693\n",
      "Epoch 829/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7405 - accuracy: 0.8505 - val_loss: 19.2540 - val_accuracy: 0.7749\n",
      "Epoch 830/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.9502 - accuracy: 0.8474 - val_loss: 19.0739 - val_accuracy: 0.7919\n",
      "Epoch 831/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8726 - accuracy: 0.8486 - val_loss: 19.2021 - val_accuracy: 0.7730\n",
      "Epoch 832/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.6096 - accuracy: 0.8503 - val_loss: 19.1219 - val_accuracy: 0.7689\n",
      "Epoch 833/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0096 - accuracy: 0.8405 - val_loss: 19.5238 - val_accuracy: 0.7756\n",
      "Epoch 834/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.2399 - accuracy: 0.8376 - val_loss: 19.3251 - val_accuracy: 0.7710\n",
      "Epoch 835/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0089 - accuracy: 0.8481 - val_loss: 19.3361 - val_accuracy: 0.7745\n",
      "Epoch 836/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8742 - accuracy: 0.8452 - val_loss: 18.8382 - val_accuracy: 0.7917\n",
      "Epoch 837/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5762 - accuracy: 0.8561 - val_loss: 19.6999 - val_accuracy: 0.7790\n",
      "Epoch 838/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0146 - accuracy: 0.8553 - val_loss: 19.0744 - val_accuracy: 0.7914\n",
      "Epoch 839/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.1886 - accuracy: 0.8443 - val_loss: 19.0267 - val_accuracy: 0.7872\n",
      "Epoch 840/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.1421 - accuracy: 0.8507 - val_loss: 19.4772 - val_accuracy: 0.7693\n",
      "Epoch 841/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.1217 - accuracy: 0.8460 - val_loss: 19.2781 - val_accuracy: 0.7943\n",
      "Epoch 842/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.2569 - accuracy: 0.8457 - val_loss: 18.8491 - val_accuracy: 0.7852\n",
      "Epoch 843/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0282 - accuracy: 0.8568 - val_loss: 18.8447 - val_accuracy: 0.7818\n",
      "Epoch 844/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.1014 - accuracy: 0.8473 - val_loss: 19.0677 - val_accuracy: 0.7885\n",
      "Epoch 845/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.4234 - accuracy: 0.8410 - val_loss: 20.1441 - val_accuracy: 0.7605\n",
      "Epoch 846/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.3169 - accuracy: 0.8467 - val_loss: 18.7272 - val_accuracy: 0.7854\n",
      "Epoch 847/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.7974 - accuracy: 0.8424 - val_loss: 18.7203 - val_accuracy: 0.7842\n",
      "Epoch 848/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0394 - accuracy: 0.8453 - val_loss: 20.2277 - val_accuracy: 0.7519\n",
      "Epoch 849/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.7794 - accuracy: 0.8283 - val_loss: 19.6553 - val_accuracy: 0.7668\n",
      "Epoch 850/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.3446 - accuracy: 0.8282 - val_loss: 19.4903 - val_accuracy: 0.7741\n",
      "Epoch 851/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.3142 - accuracy: 0.8353 - val_loss: 20.6790 - val_accuracy: 0.7479\n",
      "Epoch 852/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0040 - accuracy: 0.8475 - val_loss: 18.6302 - val_accuracy: 0.7766\n",
      "Epoch 853/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8935 - accuracy: 0.8435 - val_loss: 18.8137 - val_accuracy: 0.7856\n",
      "Epoch 854/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.1990 - accuracy: 0.8539 - val_loss: 20.0552 - val_accuracy: 0.7745\n",
      "Epoch 855/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.4098 - accuracy: 0.8523 - val_loss: 19.7157 - val_accuracy: 0.7904\n",
      "Epoch 856/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.4701 - accuracy: 0.8481 - val_loss: 19.6475 - val_accuracy: 0.7779\n",
      "Epoch 857/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8200 - accuracy: 0.8536 - val_loss: 18.7814 - val_accuracy: 0.7743\n",
      "Epoch 858/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8668 - accuracy: 0.8419 - val_loss: 19.4691 - val_accuracy: 0.7762\n",
      "Epoch 859/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.3259 - accuracy: 0.8375 - val_loss: 20.3872 - val_accuracy: 0.7580\n",
      "Epoch 860/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.2939 - accuracy: 0.8466 - val_loss: 19.6918 - val_accuracy: 0.7786\n",
      "Epoch 861/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.1465 - accuracy: 0.8470 - val_loss: 19.2244 - val_accuracy: 0.7846\n",
      "Epoch 862/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8456 - accuracy: 0.8529 - val_loss: 19.5443 - val_accuracy: 0.7683\n",
      "Epoch 863/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8192 - accuracy: 0.8489 - val_loss: 18.7177 - val_accuracy: 0.7811\n",
      "Epoch 864/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.5314 - accuracy: 0.8430 - val_loss: 18.7114 - val_accuracy: 0.7751\n",
      "Epoch 865/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0968 - accuracy: 0.8415 - val_loss: 20.2181 - val_accuracy: 0.7590\n",
      "Epoch 866/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0217 - accuracy: 0.8456 - val_loss: 18.9346 - val_accuracy: 0.7798\n",
      "Epoch 867/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0726 - accuracy: 0.8422 - val_loss: 19.2248 - val_accuracy: 0.7798\n",
      "Epoch 868/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.4748 - accuracy: 0.8486 - val_loss: 20.3403 - val_accuracy: 0.7667\n",
      "Epoch 869/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.3573 - accuracy: 0.8505 - val_loss: 19.6211 - val_accuracy: 0.7844\n",
      "Epoch 870/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.1789 - accuracy: 0.8408 - val_loss: 19.0841 - val_accuracy: 0.7769\n",
      "Epoch 871/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.8476 - accuracy: 0.8425 - val_loss: 19.8244 - val_accuracy: 0.7532\n",
      "Epoch 872/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.1959 - accuracy: 0.8275 - val_loss: 19.0924 - val_accuracy: 0.7779\n",
      "Epoch 873/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 7.4984 - accuracy: 0.8457 - val_loss: 18.9789 - val_accuracy: 0.7801\n",
      "Epoch 874/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.0457 - accuracy: 0.8553 - val_loss: 20.2136 - val_accuracy: 0.7794\n",
      "Epoch 875/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.4487 - accuracy: 0.8538 - val_loss: 20.0522 - val_accuracy: 0.7960\n",
      "Epoch 876/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.4572 - accuracy: 0.8463 - val_loss: 20.8822 - val_accuracy: 0.7693\n",
      "Epoch 877/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.4761 - accuracy: 0.8468 - val_loss: 20.1152 - val_accuracy: 0.7794\n",
      "Epoch 878/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.5023 - accuracy: 0.8389 - val_loss: 20.5074 - val_accuracy: 0.7753\n",
      "Epoch 879/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.7913 - accuracy: 0.8449 - val_loss: 21.0519 - val_accuracy: 0.7655\n",
      "Epoch 880/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.1543 - accuracy: 0.8495 - val_loss: 19.8557 - val_accuracy: 0.7889\n",
      "Epoch 881/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.6861 - accuracy: 0.8435 - val_loss: 20.7522 - val_accuracy: 0.7695\n",
      "Epoch 882/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.8096 - accuracy: 0.8513 - val_loss: 19.1331 - val_accuracy: 0.7859\n",
      "Epoch 883/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.8218 - accuracy: 0.8379 - val_loss: 19.9808 - val_accuracy: 0.7841\n",
      "Epoch 884/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.4688 - accuracy: 0.8438 - val_loss: 21.5506 - val_accuracy: 0.7558\n",
      "Epoch 885/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.0338 - accuracy: 0.8343 - val_loss: 19.5434 - val_accuracy: 0.7854\n",
      "Epoch 886/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.5474 - accuracy: 0.8364 - val_loss: 19.2422 - val_accuracy: 0.7777\n",
      "Epoch 887/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.6069 - accuracy: 0.8487 - val_loss: 20.2180 - val_accuracy: 0.7730\n",
      "Epoch 888/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.0360 - accuracy: 0.8390 - val_loss: 21.3187 - val_accuracy: 0.7807\n",
      "Epoch 889/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.4308 - accuracy: 0.8403 - val_loss: 21.4184 - val_accuracy: 0.7597\n",
      "Epoch 890/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.8006 - accuracy: 0.8468 - val_loss: 19.5255 - val_accuracy: 0.7839\n",
      "Epoch 891/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.6617 - accuracy: 0.8342 - val_loss: 18.8036 - val_accuracy: 0.7842\n",
      "Epoch 892/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.1874 - accuracy: 0.8536 - val_loss: 20.7934 - val_accuracy: 0.7711\n",
      "Epoch 893/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.3049 - accuracy: 0.8439 - val_loss: 20.1553 - val_accuracy: 0.7876\n",
      "Epoch 894/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.2190 - accuracy: 0.8368 - val_loss: 19.5340 - val_accuracy: 0.7805\n",
      "Epoch 895/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.3000 - accuracy: 0.8466 - val_loss: 18.8337 - val_accuracy: 0.7824\n",
      "Epoch 896/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.1874 - accuracy: 0.8299 - val_loss: 18.4314 - val_accuracy: 0.7906\n",
      "Epoch 897/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.2349 - accuracy: 0.8481 - val_loss: 20.6360 - val_accuracy: 0.7721\n",
      "Epoch 898/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.9249 - accuracy: 0.8332 - val_loss: 20.5999 - val_accuracy: 0.7829\n",
      "Epoch 899/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.3188 - accuracy: 0.8476 - val_loss: 20.7258 - val_accuracy: 0.7741\n",
      "Epoch 900/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.4166 - accuracy: 0.8443 - val_loss: 20.9404 - val_accuracy: 0.7811\n",
      "Epoch 901/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.3747 - accuracy: 0.8419 - val_loss: 20.7348 - val_accuracy: 0.7792\n",
      "Epoch 902/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.9598 - accuracy: 0.8489 - val_loss: 21.0762 - val_accuracy: 0.7620\n",
      "Epoch 903/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.2541 - accuracy: 0.8407 - val_loss: 20.4111 - val_accuracy: 0.7811\n",
      "Epoch 904/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.8627 - accuracy: 0.8421 - val_loss: 19.3931 - val_accuracy: 0.7713\n",
      "Epoch 905/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.4958 - accuracy: 0.8336 - val_loss: 19.9246 - val_accuracy: 0.7700\n",
      "Epoch 906/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.3081 - accuracy: 0.8415 - val_loss: 18.9991 - val_accuracy: 0.7973\n",
      "Epoch 907/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.0343 - accuracy: 0.8440 - val_loss: 19.6738 - val_accuracy: 0.7848\n",
      "Epoch 908/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.4045 - accuracy: 0.8497 - val_loss: 19.7431 - val_accuracy: 0.7865\n",
      "Epoch 909/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.0390 - accuracy: 0.8363 - val_loss: 20.2507 - val_accuracy: 0.7736\n",
      "Epoch 910/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.8547 - accuracy: 0.8266 - val_loss: 21.5159 - val_accuracy: 0.7479\n",
      "Epoch 911/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.9202 - accuracy: 0.8352 - val_loss: 20.5046 - val_accuracy: 0.7687\n",
      "Epoch 912/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.8549 - accuracy: 0.8402 - val_loss: 21.0360 - val_accuracy: 0.7814\n",
      "Epoch 913/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.3830 - accuracy: 0.8527 - val_loss: 20.7576 - val_accuracy: 0.7689\n",
      "Epoch 914/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.6131 - accuracy: 0.8452 - val_loss: 20.9629 - val_accuracy: 0.7786\n",
      "Epoch 915/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.8005 - accuracy: 0.8401 - val_loss: 20.2996 - val_accuracy: 0.7616\n",
      "Epoch 916/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.6639 - accuracy: 0.8409 - val_loss: 20.2347 - val_accuracy: 0.7779\n",
      "Epoch 917/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.9591 - accuracy: 0.8377 - val_loss: 19.8977 - val_accuracy: 0.7801\n",
      "Epoch 918/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.6347 - accuracy: 0.8398 - val_loss: 19.4945 - val_accuracy: 0.7814\n",
      "Epoch 919/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.7927 - accuracy: 0.8454 - val_loss: 20.3572 - val_accuracy: 0.7844\n",
      "Epoch 920/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.8682 - accuracy: 0.8471 - val_loss: 20.2847 - val_accuracy: 0.7900\n",
      "Epoch 921/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.9772 - accuracy: 0.8597 - val_loss: 21.4752 - val_accuracy: 0.7850\n",
      "Epoch 922/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.0941 - accuracy: 0.8520 - val_loss: 20.6985 - val_accuracy: 0.7850\n",
      "Epoch 923/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.3081 - accuracy: 0.8517 - val_loss: 20.5463 - val_accuracy: 0.7796\n",
      "Epoch 924/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.7657 - accuracy: 0.8408 - val_loss: 20.2456 - val_accuracy: 0.7702\n",
      "Epoch 925/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.2894 - accuracy: 0.8389 - val_loss: 20.3544 - val_accuracy: 0.7863\n",
      "Epoch 926/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.7220 - accuracy: 0.8421 - val_loss: 20.7428 - val_accuracy: 0.7704\n",
      "Epoch 927/1000\n",
      "1069/1069 [==============================] - 2s 1ms/step - loss: 8.9870 - accuracy: 0.8401 - val_loss: 19.7540 - val_accuracy: 0.7801\n",
      "Epoch 928/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.1401 - accuracy: 0.8306 - val_loss: 20.6662 - val_accuracy: 0.7698\n",
      "Epoch 929/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.6393 - accuracy: 0.8239 - val_loss: 21.1447 - val_accuracy: 0.7511\n",
      "Epoch 930/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.0986 - accuracy: 0.8423 - val_loss: 20.6130 - val_accuracy: 0.7792\n",
      "Epoch 931/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.2395 - accuracy: 0.8335 - val_loss: 20.5532 - val_accuracy: 0.7833\n",
      "Epoch 932/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.1778 - accuracy: 0.8457 - val_loss: 22.0419 - val_accuracy: 0.7577\n",
      "Epoch 933/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.8539 - accuracy: 0.8364 - val_loss: 21.3398 - val_accuracy: 0.7835\n",
      "Epoch 934/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.9388 - accuracy: 0.8459 - val_loss: 20.5709 - val_accuracy: 0.7775\n",
      "Epoch 935/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.5540 - accuracy: 0.8595 - val_loss: 19.9782 - val_accuracy: 0.7912\n",
      "Epoch 936/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.8443 - accuracy: 0.8471 - val_loss: 19.8763 - val_accuracy: 0.7912\n",
      "Epoch 937/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.6859 - accuracy: 0.8534 - val_loss: 20.7710 - val_accuracy: 0.7646\n",
      "Epoch 938/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.3188 - accuracy: 0.8373 - val_loss: 20.6713 - val_accuracy: 0.7837\n",
      "Epoch 939/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.0060 - accuracy: 0.8463 - val_loss: 20.5651 - val_accuracy: 0.7775\n",
      "Epoch 940/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.3495 - accuracy: 0.8428 - val_loss: 20.5970 - val_accuracy: 0.7856\n",
      "Epoch 941/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.2115 - accuracy: 0.8439 - val_loss: 20.3138 - val_accuracy: 0.7863\n",
      "Epoch 942/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.0345 - accuracy: 0.8447 - val_loss: 21.6800 - val_accuracy: 0.7575\n",
      "Epoch 943/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.3947 - accuracy: 0.8348 - val_loss: 22.5939 - val_accuracy: 0.7816\n",
      "Epoch 944/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.7282 - accuracy: 0.8386 - val_loss: 23.4906 - val_accuracy: 0.7406\n",
      "Epoch 945/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.9878 - accuracy: 0.8414 - val_loss: 22.0361 - val_accuracy: 0.7835\n",
      "Epoch 946/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.4292 - accuracy: 0.8445 - val_loss: 20.5299 - val_accuracy: 0.7754\n",
      "Epoch 947/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.1181 - accuracy: 0.8500 - val_loss: 20.8533 - val_accuracy: 0.7726\n",
      "Epoch 948/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.2651 - accuracy: 0.8374 - val_loss: 20.8136 - val_accuracy: 0.7863\n",
      "Epoch 949/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.3627 - accuracy: 0.8353 - val_loss: 21.4750 - val_accuracy: 0.7506\n",
      "Epoch 950/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.6584 - accuracy: 0.8384 - val_loss: 20.4667 - val_accuracy: 0.7775\n",
      "Epoch 951/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.3842 - accuracy: 0.8257 - val_loss: 20.5101 - val_accuracy: 0.7762\n",
      "Epoch 952/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.8157 - accuracy: 0.8387 - val_loss: 22.1995 - val_accuracy: 0.7627\n",
      "Epoch 953/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.3638 - accuracy: 0.8475 - val_loss: 21.4726 - val_accuracy: 0.7850\n",
      "Epoch 954/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.1977 - accuracy: 0.8511 - val_loss: 22.5481 - val_accuracy: 0.7779\n",
      "Epoch 955/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.0405 - accuracy: 0.8557 - val_loss: 20.9658 - val_accuracy: 0.7788\n",
      "Epoch 956/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.1412 - accuracy: 0.8371 - val_loss: 21.7070 - val_accuracy: 0.7753\n",
      "Epoch 957/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.6317 - accuracy: 0.8355 - val_loss: 21.2844 - val_accuracy: 0.7629\n",
      "Epoch 958/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.4071 - accuracy: 0.8393 - val_loss: 20.6934 - val_accuracy: 0.7893\n",
      "Epoch 959/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.5855 - accuracy: 0.8475 - val_loss: 21.2345 - val_accuracy: 0.7876\n",
      "Epoch 960/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.6586 - accuracy: 0.8522 - val_loss: 21.1475 - val_accuracy: 0.7882\n",
      "Epoch 961/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.1603 - accuracy: 0.8512 - val_loss: 22.0575 - val_accuracy: 0.7848\n",
      "Epoch 962/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.3551 - accuracy: 0.8536 - val_loss: 21.6307 - val_accuracy: 0.7657\n",
      "Epoch 963/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.0521 - accuracy: 0.8413 - val_loss: 21.6791 - val_accuracy: 0.7792\n",
      "Epoch 964/1000\n",
      "1069/1069 [==============================] - 1s 968us/step - loss: 9.4446 - accuracy: 0.8391 - val_loss: 22.0633 - val_accuracy: 0.7594\n",
      "Epoch 965/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.4159 - accuracy: 0.8411 - val_loss: 20.2665 - val_accuracy: 0.7798\n",
      "Epoch 966/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 8.8590 - accuracy: 0.8409 - val_loss: 21.0621 - val_accuracy: 0.7865\n",
      "Epoch 967/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 10.1383 - accuracy: 0.8383 - val_loss: 23.0644 - val_accuracy: 0.7637\n",
      "Epoch 968/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 10.1682 - accuracy: 0.8436 - val_loss: 23.1414 - val_accuracy: 0.7885\n",
      "Epoch 969/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.8757 - accuracy: 0.8421 - val_loss: 22.5809 - val_accuracy: 0.7655\n",
      "Epoch 970/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.3434 - accuracy: 0.8521 - val_loss: 21.7265 - val_accuracy: 0.7764\n",
      "Epoch 971/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.6533 - accuracy: 0.8308 - val_loss: 22.2000 - val_accuracy: 0.7644\n",
      "Epoch 972/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.7880 - accuracy: 0.8340 - val_loss: 22.4471 - val_accuracy: 0.7603\n",
      "Epoch 973/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.0287 - accuracy: 0.8494 - val_loss: 20.9795 - val_accuracy: 0.7904\n",
      "Epoch 974/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.7817 - accuracy: 0.8449 - val_loss: 21.0935 - val_accuracy: 0.7856\n",
      "Epoch 975/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.9652 - accuracy: 0.8509 - val_loss: 21.5225 - val_accuracy: 0.7850\n",
      "Epoch 976/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.6747 - accuracy: 0.8430 - val_loss: 21.6383 - val_accuracy: 0.7704\n",
      "Epoch 977/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.2011 - accuracy: 0.8457 - val_loss: 22.8881 - val_accuracy: 0.7597\n",
      "Epoch 978/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.5872 - accuracy: 0.8417 - val_loss: 22.9890 - val_accuracy: 0.7605\n",
      "Epoch 979/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 10.1690 - accuracy: 0.8327 - val_loss: 22.8197 - val_accuracy: 0.7667\n",
      "Epoch 980/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.1848 - accuracy: 0.8465 - val_loss: 21.6341 - val_accuracy: 0.7682\n",
      "Epoch 981/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.8232 - accuracy: 0.8328 - val_loss: 20.9659 - val_accuracy: 0.7904\n",
      "Epoch 982/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.4535 - accuracy: 0.8481 - val_loss: 20.9700 - val_accuracy: 0.7848\n",
      "Epoch 983/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.9128 - accuracy: 0.8472 - val_loss: 22.1014 - val_accuracy: 0.7749\n",
      "Epoch 984/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.6427 - accuracy: 0.8408 - val_loss: 22.4042 - val_accuracy: 0.7706\n",
      "Epoch 985/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.2077 - accuracy: 0.8422 - val_loss: 23.4877 - val_accuracy: 0.7420\n",
      "Epoch 986/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.9638 - accuracy: 0.8273 - val_loss: 22.7690 - val_accuracy: 0.7732\n",
      "Epoch 987/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.5872 - accuracy: 0.8405 - val_loss: 22.5236 - val_accuracy: 0.7674\n",
      "Epoch 988/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.9794 - accuracy: 0.8476 - val_loss: 21.7024 - val_accuracy: 0.7904\n",
      "Epoch 989/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.9155 - accuracy: 0.8443 - val_loss: 21.2857 - val_accuracy: 0.7850\n",
      "Epoch 990/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.7101 - accuracy: 0.8496 - val_loss: 21.2775 - val_accuracy: 0.7758\n",
      "Epoch 991/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.7977 - accuracy: 0.8318 - val_loss: 22.0523 - val_accuracy: 0.7764\n",
      "Epoch 992/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.7410 - accuracy: 0.8440 - val_loss: 24.2089 - val_accuracy: 0.7481\n",
      "Epoch 993/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 10.0645 - accuracy: 0.8404 - val_loss: 23.6379 - val_accuracy: 0.7826\n",
      "Epoch 994/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 9.7126 - accuracy: 0.8465 - val_loss: 23.0171 - val_accuracy: 0.7665\n",
      "Epoch 995/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 10.2066 - accuracy: 0.8459 - val_loss: 21.5411 - val_accuracy: 0.7902\n",
      "Epoch 996/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 10.9136 - accuracy: 0.8315 - val_loss: 21.4084 - val_accuracy: 0.7865\n",
      "Epoch 997/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 10.7703 - accuracy: 0.8432 - val_loss: 22.3479 - val_accuracy: 0.7743\n",
      "Epoch 998/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 10.2808 - accuracy: 0.8416 - val_loss: 23.8918 - val_accuracy: 0.7841\n",
      "Epoch 999/1000\n",
      "1069/1069 [==============================] - 1s 990us/step - loss: 10.3015 - accuracy: 0.8430 - val_loss: 24.5491 - val_accuracy: 0.7436\n",
      "Epoch 1000/1000\n",
      "1069/1069 [==============================] - 1s 1ms/step - loss: 10.2066 - accuracy: 0.8356 - val_loss: 23.9663 - val_accuracy: 0.7768\n",
      "CPU times: user 25min 15s, sys: 3min 22s, total: 28min 37s\n",
      "Wall time: 19min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "CLASSIFICATION_EPOCHS=1_000\n",
    "\n",
    "clear_session()\n",
    "classifier=classifier_facotory(\n",
    "               input_dim=latent_dimension)\n",
    "history=(classifier \n",
    "         .fit( \n",
    "            latents_and_labels['training'][0],  \n",
    "            latents_and_labels['training'][1], \n",
    "            validation_data=tuple( \n",
    "                                latents_and_labels[\"validation\"]),\n",
    "            epochs=CLASSIFICATION_EPOCHS, \n",
    "            batch_size=BATCH[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/envs/data3/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /opt/conda/envs/data3/lib/python3.8/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: ./capstonedump/tfmodels/EfficientNetB5/assets\n"
     ]
    }
   ],
   "source": [
    "os.mkdir(f\"{TFMODELS_STORAGE}/{MODEL_SPEC}\")\n",
    "classifier.save(f\"{TFMODELS_STORAGE}/{MODEL_SPEC}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracies(in_train, \n",
    "                    in_val, \n",
    "                    **KWARGS):\n",
    "    acc_over_epochs=plt.figure()\n",
    "    acc_over_epochs.patch.set_facecolor('white')\n",
    "    acc_over_epochs.patch.alpha=.7\n",
    "    drawer=acc_over_epochs.add_subplot(111, xlabel=\"epochs\", ylabel=\"accuracy\")\n",
    "    \n",
    "    curves=[drawer.plot(history, label=subset)  \n",
    "            for subset, history  \n",
    "            in zip(OPTIMIZATION_SUBDATASETS, [in_train, in_val])]\n",
    "    handles, labels=drawer.get_legend_handles_labels()\n",
    "    plt.legend(handles, labels)\n",
    "    if (save_dir_:=KWARGS[\"saveas\"]):\n",
    "        acc_over_epochs.savefig(save_dir_)\n",
    "    return acc_over_epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_over_epochs=plot_accuracies(\n",
    "                    history.history[\"accuracy\"], \n",
    "                    history.history[\"val_accuracy\"],\n",
    "                    saveas=f\"{PLOTS_STORAGE}/temp2\")\n",
    "acc_over_epochs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_responses=np.argmax(\n",
    "                            classifier \n",
    "                            .predict( \n",
    "                                latents_and_labels[\"validation\"][0]), \n",
    "                            axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 901.,    0.,    0.,    0.,    0., 2517.,    0.,    0.,    0.,\n",
       "        1926.]),\n",
       " array([0. , 0.2, 0.4, 0.6, 0.8, 1. , 1.2, 1.4, 1.6, 1.8, 2. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(classifier_responses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jovyan/jhshi'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tag listing kitchens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "(depricated)\n",
    "Zillow profiles too hard to scrape\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "random_flip (RandomFlip)     (None, 260, 260, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_rotation (RandomRotat (None, 260, 260, 3)       0         \n",
      "_________________________________________________________________\n",
      "random_contrast (RandomContr (None, 260, 260, 3)       0         \n",
      "_________________________________________________________________\n",
      "functional_1 (Functional)    (None, 1408)              7768569   \n",
      "=================================================================\n",
      "Total params: 7,768,569\n",
      "Trainable params: 0\n",
      "Non-trainable params: 7,768,569\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "clear_session()\n",
    "transfer_student=pretrained_factory(\n",
    "                     img_size=IMG_SIZE[MODEL_SPEC],\n",
    "                     num_layers_to_exclude=2,\n",
    "                     rotation_factor=0.1,\n",
    "                     contrast_factor=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "address_images=[(file.split('.')[0], \n",
    " tf.image.resize(\n",
    "              img_to_array(\n",
    "              Image.open(f\"{LISTING_SOURCE}/{file}\")),\n",
    "              [IMG_SIZE[MODEL_SPEC], \n",
    "               IMG_SIZE[MODEL_SPEC]]))\n",
    " for file \n",
    " in os.listdir(f\"{LISTING_SOURCE}/\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step\n",
      "CPU times: user 4.51 s, sys: 232 ms, total: 4.74 s\n",
      "Wall time: 2.45 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "latent=transfer_student.predict(tf.stack([duo[1] for duo in address_images]), verbose=1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{MAIN_STORAGE}/latents-listings-and-addresses-{MODEL_SPEC}.pkd\", \"wb\") as writefile:\n",
    "    dill.dump(\n",
    "        ([duo[0] for duo in address_images],\n",
    "         latent),\n",
    "        writefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=classifier_facotory(input_dim=latent.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1408"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latent.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier=load_model(TFMODELS_STORAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'sequential',\n",
       " 'layers': [{'class_name': 'InputLayer',\n",
       "   'config': {'batch_input_shape': (None, 1408),\n",
       "    'dtype': 'float32',\n",
       "    'sparse': False,\n",
       "    'ragged': False,\n",
       "    'name': 'softmax_input'}},\n",
       "  {'class_name': 'Dense',\n",
       "   'config': {'name': 'softmax',\n",
       "    'trainable': True,\n",
       "    'batch_input_shape': (None, 1408),\n",
       "    'dtype': 'float32',\n",
       "    'units': 3,\n",
       "    'activation': 'softmax',\n",
       "    'use_bias': True,\n",
       "    'kernel_initializer': {'class_name': 'GlorotUniform',\n",
       "     'config': {'seed': None}},\n",
       "    'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       "    'kernel_regularizer': None,\n",
       "    'bias_regularizer': None,\n",
       "    'activity_regularizer': None,\n",
       "    'kernel_constraint': None,\n",
       "    'bias_constraint': None}}]}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_predictions=np.argmax(classifier.predict(tf.convert_to_tensor(latent)),\n",
    "                            axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "address_ratings={k:v \n",
    "                 for k,v in zip([duo[0] \n",
    "                                 for duo in address_images], model_predictions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1326-Diamond-St-kitchen': 2,\n",
       " '635-Joost-Ave-kitchen': 2,\n",
       " '1933-B-Jones-St-kitchen': 2,\n",
       " '8420-Birch-St-kitchen': 2,\n",
       " '62-Natick-St-kitchen': 2,\n",
       " '6424-Foothill-Blvd-kitchen': 2,\n",
       " '851-34th-Ave-kitchen': 2,\n",
       " '708-Long-Bridge-St-APT-110-kitchen': 2,\n",
       " '101-Upper-Ter-kitchen': 2,\n",
       " '1311-Guerrero-St-APT-1-kitchen': 1,\n",
       " '815-Pacheco-St-kitchen': 0,\n",
       " '1238-Sutter-St-#501-kitchen': 2,\n",
       " '181-Lucky-St-kitchen': 2,\n",
       " '1370-Quesada-Ave-kitchen': 2,\n",
       " '353-San-Jose-Ave-kitchen': 2}"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "address_ratings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
